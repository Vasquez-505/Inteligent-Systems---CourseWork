{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasquez-505/Inteligent-Systems---CourseWork/blob/main/docs/notebooks/Training_and_inference_using_Google_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpGZS1aI4ssO"
      },
      "source": [
        "# Training and inference on your own data using Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xp-A8Oc80Q"
      },
      "source": [
        "In this notebook we'll install SLEAP, import training data into Colab using [Google Drive](https://www.google.com/drive), and run training and inference."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"sleap[nn]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vahdHV_v-vvY",
        "outputId": "27e2a450-8890-405b-cb34-bea698d08aff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sleap[nn] in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (25.4.0)\n",
            "Requirement already satisfied: cattrs in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (25.3.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.6.0)\n",
            "Requirement already satisfied: imgstore in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.3.7)\n",
            "Requirement already satisfied: jsmin in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (3.0.1)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (4.1.1)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (3.0.3)\n",
            "Requirement already satisfied: ndx-pose in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (3.5)\n",
            "Requirement already satisfied: nixio in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (1.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (5.9.5)\n",
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.10.2)\n",
            "Requirement already satisfied: pynwb in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (3.1.2)\n",
            "Requirement already satisfied: PySide6 in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (6.10.0)\n",
            "Requirement already satisfied: python-rapidjson in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (1.21)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (6.0.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (26.2.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.4.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (13.9.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (1.16.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (0.13.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.5.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from sleap[nn]) (3.10.0)\n",
            "Requirement already satisfied: sleap-io>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from sleap-io[all]>=0.5.3->sleap[nn]) (0.5.5)\n",
            "Collecting sleap-nn>=0.0.2 (from sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading sleap_nn-0.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: h5py>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from sleap-io>=0.5.3->sleap-io[all]>=0.5.3->sleap[nn]) (3.14.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from sleap-io>=0.5.3->sleap-io[all]>=0.5.3->sleap[nn]) (3.20.2)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (from sleap-io>=0.5.3->sleap-io[all]>=0.5.3->sleap[nn]) (2025.10.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sleap-io>=0.5.3->sleap-io[all]>=0.5.3->sleap[nn]) (4.67.1)\n",
            "Requirement already satisfied: hdmf>=3.13.0 in /usr/local/lib/python3.12/dist-packages (from ndx-pose->sleap[nn]) (4.1.0)\n",
            "Requirement already satisfied: platformdirs>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from pynwb->sleap[nn]) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pynwb->sleap[nn]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->sleap[nn]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->sleap[nn]) (2025.2)\n",
            "Requirement already satisfied: av<16.0.0 in /usr/local/lib/python3.12/dist-packages (from sleap-io[all]>=0.5.3->sleap[nn]) (15.1.0)\n",
            "Requirement already satisfied: pymatreader in /usr/local/lib/python3.12/dist-packages (from sleap-io[all]>=0.5.3->sleap[nn]) (1.1.0)\n",
            "Collecting lightning (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting kornia (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.22.2)\n",
            "Collecting loguru (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hydra-core (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting jupyter (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting jupyterlab (from sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading jupyterlab-4.4.9-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.23.0+cu126)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->sleap[nn]) (2.11.10)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->sleap[nn]) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->sleap[nn]) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->sleap[nn]) (4.2.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->sleap[nn]) (6.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from cattrs->sleap[nn]) (4.15.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio->sleap[nn]) (11.3.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from imgstore->sleap[nn]) (5.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sleap[nn]) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from nixio->sleap[nn]) (1.17.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->sleap[nn]) (4.9.3)\n",
            "Requirement already satisfied: scikit-base<0.13.0 in /usr/local/lib/python3.12/dist-packages (from pykalman->sleap[nn]) (0.12.6)\n",
            "Requirement already satisfied: shiboken6==6.10.0 in /usr/local/lib/python3.12/dist-packages (from PySide6->sleap[nn]) (6.10.0)\n",
            "Requirement already satisfied: PySide6_Essentials==6.10.0 in /usr/local/lib/python3.12/dist-packages (from PySide6->sleap[nn]) (6.10.0)\n",
            "Requirement already satisfied: PySide6_Addons==6.10.0 in /usr/local/lib/python3.12/dist-packages (from PySide6->sleap[nn]) (6.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->sleap[nn]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->sleap[nn]) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->sleap[nn]) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->sleap[nn]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->sleap[nn]) (2.19.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->sleap[nn]) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sleap[nn]) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sleap[nn]) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from hdmf>=3.13.0->ndx-pose->sleap[nn]) (4.25.1)\n",
            "Requirement already satisfied: ruamel-yaml>=0.16 in /usr/local/lib/python3.12/dist-packages (from hdmf>=3.13.0->ndx-pose->sleap[nn]) (0.18.15)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->sleap[nn]) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->sleap[nn]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->sleap[nn]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->sleap[nn]) (0.4.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (7.7.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (5.8.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (5.7.1)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.4.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-lightning (from lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (from pymatreader->sleap-io[all]>=0.5.3->sleap[nn]) (1.0.2)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.1.45)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (5.29.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.40.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.6.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->hdmf>=3.13.0->ndx-pose->sleap[nn]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->hdmf>=3.13.0->ndx-pose->sleap[nn]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->hdmf>=3.13.0->ndx-pose->sleap[nn]) (0.27.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.5.3)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.23.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.9.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.5.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel-yaml>=0.16->hdmf>=3.13.0->ndx-pose->sleap[nn]) (0.2.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.0.15)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.0.52)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.22.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (5.0.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.1.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.2.14)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (0.8.5)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (24.11.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->sleap-nn>=0.0.2->sleap-nn[torch]>=0.0.2; extra == \"nn\"->sleap[nn]) (2.9.0.20251008)\n",
            "Downloading sleap_nn-0.0.2-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.4.9-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru, lightning-utilities, kornia_rs, json5, jedi, async-lru, hydra-core, torchmetrics, kornia, pytorch-lightning, lightning, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, sleap-nn\n",
            "Successfully installed async-lru-2.0.5 hydra-core-1.3.2 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.4.9 jupyterlab-server-2.27.3 kornia-0.8.1 kornia_rs-0.1.9 lightning-2.5.5 lightning-utilities-0.15.2 loguru-0.7.3 pytorch-lightning-2.5.5 sleap-nn-0.0.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX9noEb8m8re"
      },
      "source": [
        "## Install SLEAP\n",
        "Note: Before installing SLEAP check [SLEAP releases](https://github.com/talmolab/sleap/releases) page for the latest version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfnkxMtLcK3",
        "outputId": "e5b7606d-ee9a-4aed-c290-30a1b440cda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: sleap 1.5.1 does not provide the extra 'pypi'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m878.8/878.8 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m911.5/911.5 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.4/249.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.8/557.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.2/170.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.1/271.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.7/336.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nixio (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]>=1.3.3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7jrgUksLtR"
      },
      "source": [
        "## Import training data into Colab with Google Drive\n",
        "We'll first prepare and export the training data from SLEAP, then upload it to Google Drive, and then mount Google Drive  into this Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwpEwrxYdLMR"
      },
      "source": [
        "### Create and export the training job package\n",
        "A self-contained **training job package** contains a .slp file with labeled data and images which will be used for training, as well as .json training configuration file(s).\n",
        "\n",
        "A training job package can be exported in the SLEAP GUI fron the \"Run Training..\" dialog under the \"Predict\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApaDWxW4dLMS"
      },
      "source": [
        "### Upload training job package to Google Drive\n",
        "To be consistent with the examples in this notebook, name the SLEAP project `colab` and create a directory called `sleap` in the root of your Google Drive. Then upload the exported training job package `colab.slp.training_job.zip` into `sleap` directory.\n",
        "\n",
        "If you place your training pckage somewhere else, or name it differently, adjust the paths/filenames/parameters below accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HCGgy4kdLMS",
        "tags": []
      },
      "source": [
        "### Mount your Google Drive\n",
        "Mounting your Google Drive will allow you to accessed the uploaded training job package in this notebook. When prompted to log into your Google account, give Colab access and the copy the authorization code into a field below (+ hit 'return')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBWjF4jpMG2N",
        "outputId": "1b287801-c717-4e5e-bf73-3b2aae3355dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhv_gsdJzaq"
      },
      "source": [
        "Let's set your current working directory to the directory with your training job package and unpack it there. Later on the output from training (i.e., the models) and from interence (i.e., predictions) will all be saved in this directory as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umui-gI2rBz",
        "outputId": "06a819b3-d157-43a1-f985-dbdc61ef5980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  colab.slp.training_job.zip\n",
            "replace CantonS_unamp_Fly1.3/colab.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/colab.slp  \n",
            "replace CantonS_unamp_Fly1.3/fly1.1.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace CantonS_unamp_Fly1.3/fly1.1.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly1.1.mp4  \n",
            "replace CantonS_unamp_Fly1.3/fly1.2.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly1.2.mp4  \n",
            "replace CantonS_unamp_Fly1.3/fly14.1.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly14.1.mp4  \n",
            "replace CantonS_unamp_Fly1.3/fly4.1.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly4.1.mp4  \n",
            "replace CantonS_unamp_Fly1.3/fly6.2.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly6.2.mp4  \n",
            "replace CantonS_unamp_Fly1.3/fly7.1.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/fly7.1.mp4  \n",
            "replace CantonS_unamp_Fly1.3/inference-script.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/inference-script.sh  \n",
            "replace CantonS_unamp_Fly1.3/jobs.yaml? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/jobs.yaml  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/best_model.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/best_model.h5  y\n",
            "\n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/initial_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/initial_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_gt.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_gt.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_gt.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_gt.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_pr.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_pr.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_pr.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/labels_pr.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/metrics.train.npz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/metrics.train.npz  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/metrics.val.npz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/metrics.val.npz  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/training_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: error:  invalid response [{ENTER}]\n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/training_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/training_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/training_log.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251007_193326.single_instance.n=40/training_log.csv  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/best_model.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/best_model.h5  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/initial_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/initial_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_gt.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_gt.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_gt.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_gt.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_pr.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_pr.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_pr.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/labels_pr.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/metrics.train.npz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/metrics.train.npz  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/metrics.val.npz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/metrics.val.npz  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/training_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/training_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/training_log.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/251008_163824.single_instance.n=40/training_log.csv  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/best_model.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/best_model.h5  y\n",
            "\n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/initial_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/initial_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_gt.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_gt.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_gt.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_gt.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_pr.train.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_pr.train.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_pr.val.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/labels_pr.val.slp  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/train/events.out.tfevents.1760477150.DESKTOP-LTGC20P.27520.0.v2? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/train/events.out.tfevents.1760477150.DESKTOP-LTGC20P.27520.0.v2  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/train/events.out.tfevents.1760477165.DESKTOP-LTGC20P.27520.2.v2? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/train/events.out.tfevents.1760477165.DESKTOP-LTGC20P.27520.2.v2  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/training_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/training_config.json  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/training_log.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/training_log.csv  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/validation/events.out.tfevents.1760477150.DESKTOP-LTGC20P.27520.1.v2? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/validation/events.out.tfevents.1760477150.DESKTOP-LTGC20P.27520.1.v2  \n",
            "replace CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/validation/events.out.tfevents.1760477652.DESKTOP-LTGC20P.27520.3.v2? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/models/unet_fly_v1251014_222526.single_instance.n=461/validation/events.out.tfevents.1760477652.DESKTOP-LTGC20P.27520.3.v2  \n",
            "replace CantonS_unamp_Fly1.3/output.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/output.mp4  \n",
            "replace CantonS_unamp_Fly1.3/predictions/fly1_3.v001.slp.251008_180404.predictions.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/predictions/fly1_3.v001.slp.251008_180404.predictions.slp  \n",
            "replace CantonS_unamp_Fly1.3/predictions/fly1_3.v001.slp.251008_182545.predictions.slp? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/predictions/fly1_3.v001.slp.251008_182545.predictions.slp  \n",
            "replace CantonS_unamp_Fly1.3/single_instance.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/single_instance.json  \n",
            "replace CantonS_unamp_Fly1.3/skeleton.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/skeleton.json  \n",
            "replace CantonS_unamp_Fly1.3/train-script.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: CantonS_unamp_Fly1.3/train-script.sh  \n",
            "CantonS_unamp_Fly1.3  colab.slp.training_job.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/sleap/colab\")\n",
        "!unzip colab.slp.training_job.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "Let's train a model with the training profile (.json file) and the project data (.slp file) you have exported from SLEAP.\n",
        "\n",
        "\n",
        "### Note on training profiles\n",
        "Depending on the pipeline you chose in the training dialog, the config filename(s) will be:\n",
        "\n",
        "- for a **bottom-up** pipeline approach: `multi_instance.json` (this is the pipeline we assume here),\n",
        "\n",
        "- for a **top-down** pipeline, you'll have a different profile for each of the models: `centroid.json` and `centered_instance.json`,\n",
        "\n",
        "- for a **single animal** pipeline: `single_instance.json`.\n",
        "\n",
        "\n",
        "### Note on training process\n",
        "When you start training, you'll first see the training parameters and then the training and validation loss for each training epoch.\n",
        "\n",
        "As soon as you're satisfied with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference.\n",
        "\n",
        "If you don't stop training, it will run for 200 epochs or until validation loss fails to improve for some number of epochs (controlled by the early_stopping fields in the training profile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QKf6qzMqNBUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a127ad-c23d-474e-ed5c-ae01adc743ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.9M\n",
            "-rw------- 1 root root 153K Oct 14 12:17 colab.slp\n",
            "-rw------- 1 root root 246K Oct  8 17:56 fly1.1.mp4\n",
            "-rw------- 1 root root 175K Oct  8 17:57 fly1.2.mp4\n",
            "-rw------- 1 root root 254K Oct 11 20:27 fly14.1.mp4\n",
            "-rw------- 1 root root 277K Oct  9 12:39 fly4.1.mp4\n",
            "-rw------- 1 root root 199K Oct  8 17:59 fly6.2.mp4\n",
            "-rw------- 1 root root 351K Oct  8 18:02 fly7.1.mp4\n",
            "-rw------- 1 root root   13 Oct 14 21:14 inference-script.sh\n",
            "-rw------- 1 root root  149 Oct 14 21:14 jobs.yaml\n",
            "drwx------ 5 root root 4.0K Oct 14 21:25 models\n",
            "-rw------- 1 root root 255K Oct  5 11:34 output.mp4\n",
            "drwx------ 2 root root 4.0K Oct 15 08:35 predictions\n",
            "-rw------- 1 root root 5.2K Oct 14 21:14 single_instance.json\n",
            "-rw------- 1 root root 2.4K Oct  5 09:34 skeleton.json\n",
            "-rw------- 1 root root   63 Oct 14 21:14 train-script.sh\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3\")\n",
        "!ls -lh \"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "===============================================================================\n",
        "SLEAP MASTER CONFIGURATION SCRIPT\n",
        "===============================================================================\n",
        "\n",
        "Description:\n",
        "    This script provides full, explicit control over all parameters in the\n",
        "    SLEAP single-instance (single-animal) training configuration file.\n",
        "    It allows you to easily modify dataset paths, model architecture (UNet,\n",
        "    ResNet, Hourglass, LEAP, or pretrained encoder), data preprocessing,\n",
        "    augmentations, optimization, and output logging parameters.\n",
        "\n",
        "Usage:\n",
        "    - Use this script for the **first-time setup** of a training environment\n",
        "      or when you need to make **structural changes** to the model or dataset.\n",
        "    - Automatically generates a timestamped run name for each experiment.\n",
        "    - Saves all modifications back to the JSON config in Google Drive.\n",
        "\n",
        "Typical workflow:\n",
        "    1️. Update model_type (e.g., \"unet\", \"resnet\", etc.)\n",
        "    2️. Adjust batch size, learning rate, and augmentation settings\n",
        "    3️. Run this cell in Colab to rewrite the JSON config\n",
        "    4️. Start training with:\n",
        "        !sleap-train single_instance.json colab.slp\n",
        "\n",
        "Output:\n",
        "    - Overwrites the selected single_instance.json with all chosen parameters.\n",
        "    - Prints a configuration summary (epochs, batch size, learning rate, etc.)\n",
        "    - Logs the active backbone type and current run name.\n",
        "\n",
        "Authors: Pedro Vasques + Chat GPT-5\n",
        "Version: Stable research configuration template\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "MODEL_NAME = \"unet_fly_v1_\"     # change this for each new model run\n",
        "EXPERIMENT_TAGS = [\"drosophila_single\"]  # add tags for clarity if needed\n",
        "\n",
        "# ==============================================================\n",
        "# 🗂️ PATHS\n",
        "# ==============================================================\n",
        "\n",
        "CONFIG_PATH = \"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/single_instance.json\"\n",
        "LABELS_PATH = \"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/colab.slp\"\n",
        "\n",
        "# === LOAD EXISTING CONFIG ===\n",
        "with open(CONFIG_PATH) as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "# ==============================================================\n",
        "# 🧠 1️⃣ DATA CONFIGURATION\n",
        "# ==============================================================\n",
        "\n",
        "cfg[\"data\"][\"labels\"][\"training_labels\"] = LABELS_PATH\n",
        "cfg[\"data\"][\"labels\"][\"validation_labels\"] = None\n",
        "cfg[\"data\"][\"labels\"][\"validation_fraction\"] = 0.1\n",
        "cfg[\"data\"][\"labels\"][\"test_labels\"] = None\n",
        "cfg[\"data\"][\"labels\"][\"split_by_inds\"] = False\n",
        "cfg[\"data\"][\"labels\"][\"skeletons\"] = []\n",
        "\n",
        "# --- Preprocessing ---\n",
        "cfg[\"data\"][\"preprocessing\"][\"ensure_rgb\"] = False\n",
        "cfg[\"data\"][\"preprocessing\"][\"ensure_grayscale\"] = False\n",
        "cfg[\"data\"][\"preprocessing\"][\"imagenet_mode\"] = None\n",
        "cfg[\"data\"][\"preprocessing\"][\"input_scaling\"] = 1.0\n",
        "cfg[\"data\"][\"preprocessing\"][\"pad_to_stride\"] = None\n",
        "cfg[\"data\"][\"preprocessing\"][\"resize_and_pad_to_target\"] = True\n",
        "cfg[\"data\"][\"preprocessing\"][\"target_height\"] = None\n",
        "cfg[\"data\"][\"preprocessing\"][\"target_width\"] = None\n",
        "\n",
        "# --- Instance cropping ---\n",
        "cfg[\"data\"][\"instance_cropping\"][\"center_on_part\"] = None\n",
        "cfg[\"data\"][\"instance_cropping\"][\"crop_size\"] = None\n",
        "cfg[\"data\"][\"instance_cropping\"][\"crop_size_detection_padding\"] = 16\n",
        "\n",
        "# ==============================================================\n",
        "# 🏗️ 2️⃣ MODEL CONFIGURATION\n",
        "# ==============================================================\n",
        "\n",
        "# Choose your backbone: \"unet\", \"resnet\", \"hourglass\", \"leap\", \"pretrained_encoder\"\n",
        "model_type = \"unet\"\n",
        "\n",
        "# Reset all backbones\n",
        "cfg[\"model\"][\"backbone\"][\"unet\"] = None\n",
        "cfg[\"model\"][\"backbone\"][\"resnet\"] = None\n",
        "cfg[\"model\"][\"backbone\"][\"hourglass\"] = None\n",
        "cfg[\"model\"][\"backbone\"][\"leap\"] = None\n",
        "cfg[\"model\"][\"backbone\"][\"pretrained_encoder\"] = None\n",
        "\n",
        "# --- Backbone definitions ---\n",
        "if model_type == \"unet\":\n",
        "    cfg[\"model\"][\"backbone\"][\"unet\"] = {\n",
        "        \"stem_stride\": None,\n",
        "        \"max_stride\": 32,\n",
        "        \"output_stride\": 4,\n",
        "        \"filters\": 32,\n",
        "        \"filters_rate\": 1.5,\n",
        "        \"middle_block\": True,\n",
        "        \"up_interpolate\": True,\n",
        "        \"stacks\": 1\n",
        "    }\n",
        "\n",
        "elif model_type == \"resnet\":\n",
        "    cfg[\"model\"][\"backbone\"][\"resnet\"] = {\n",
        "        \"architecture\": \"resnet50\",  # or \"resnet101\"\n",
        "        \"output_stride\": 16,\n",
        "        \"filters\": 64,\n",
        "        \"pretrained\": True\n",
        "    }\n",
        "\n",
        "elif model_type == \"hourglass\":\n",
        "    cfg[\"model\"][\"backbone\"][\"hourglass\"] = {\n",
        "        \"stacks\": 2,\n",
        "        \"filters\": 128,\n",
        "        \"max_stride\": 32\n",
        "    }\n",
        "\n",
        "elif model_type == \"leap\":\n",
        "    cfg[\"model\"][\"backbone\"][\"leap\"] = {\n",
        "        \"filters\": 64,\n",
        "        \"stacks\": 1,\n",
        "        \"output_stride\": 4,\n",
        "        \"filters_rate\": 1.5\n",
        "    }\n",
        "\n",
        "elif model_type == \"pretrained_encoder\":\n",
        "    cfg[\"model\"][\"backbone\"][\"pretrained_encoder\"] = {\n",
        "        \"architecture\": \"mobilenet_v2\",  # \"mobilenet_v2\", \"efficientnet_b0\", \"resnet50\"\n",
        "        \"trainable\": True,\n",
        "        \"output_stride\": 16,\n",
        "        \"filters\": 32\n",
        "    }\n",
        "\n",
        "print(f\"✅ Using backbone: {model_type.upper()}\")\n",
        "\n",
        "# --- Head configuration (single-instance only) ---\n",
        "cfg[\"model\"][\"heads\"][\"single_instance\"][\"sigma\"] = 2.5\n",
        "cfg[\"model\"][\"heads\"][\"single_instance\"][\"output_stride\"] = 4\n",
        "cfg[\"model\"][\"heads\"][\"single_instance\"][\"loss_weight\"] = 1.0\n",
        "cfg[\"model\"][\"heads\"][\"single_instance\"][\"offset_refinement\"] = False\n",
        "\n",
        "cfg[\"model\"][\"base_checkpoint\"] = None  # optional for transfer learning\n",
        "\n",
        "# ==============================================================\n",
        "# ⚙️ 3️⃣ OPTIMIZATION CONFIGURATION\n",
        "# ==============================================================\n",
        "\n",
        "cfg[\"optimization\"][\"batch_size\"] = 6\n",
        "cfg[\"optimization\"][\"epochs\"] = 200\n",
        "cfg[\"optimization\"][\"optimizer\"] = \"adam\"\n",
        "cfg[\"optimization\"][\"initial_learning_rate\"] = 1e-4\n",
        "cfg[\"optimization\"][\"online_shuffling\"] = True\n",
        "cfg[\"optimization\"][\"shuffle_buffer_size\"] = 128\n",
        "cfg[\"optimization\"][\"prefetch\"] = True\n",
        "cfg[\"optimization\"][\"batches_per_epoch\"] = None\n",
        "cfg[\"optimization\"][\"min_batches_per_epoch\"] = 200\n",
        "cfg[\"optimization\"][\"val_batches_per_epoch\"] = None\n",
        "cfg[\"optimization\"][\"min_val_batches_per_epoch\"] = 10\n",
        "\n",
        "# --- Learning rate schedule ---\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"reduce_on_plateau\"] = True\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"reduction_factor\"] = 0.5\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"plateau_min_delta\"] = 1e-6\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"plateau_patience\"] = 5\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"plateau_cooldown\"] = 3\n",
        "cfg[\"optimization\"][\"learning_rate_schedule\"][\"min_learning_rate\"] = 1e-8\n",
        "\n",
        "# --- Augmentation ---\n",
        "aug = cfg[\"optimization\"][\"augmentation_config\"]\n",
        "aug.update({\n",
        "    \"rotate\": True,\n",
        "    \"rotation_min_angle\": -15,\n",
        "    \"rotation_max_angle\": 15,\n",
        "    \"translate\": False,\n",
        "    \"translate_min\": -5,\n",
        "    \"translate_max\": 5,\n",
        "    \"scale\": True,\n",
        "    \"scale_min\": 0.9,\n",
        "    \"scale_max\": 1.1,\n",
        "    \"uniform_noise\": False,\n",
        "    \"gaussian_noise\": True,\n",
        "    \"gaussian_noise_mean\": 5.0,\n",
        "    \"gaussian_noise_stddev\": 1.0,\n",
        "    \"contrast\": True,\n",
        "    \"contrast_min_gamma\": 0.5,\n",
        "    \"contrast_max_gamma\": 2.0,\n",
        "    \"brightness\": True,\n",
        "    \"brightness_min_val\": 0.0,\n",
        "    \"brightness_max_val\": 10.0,\n",
        "    \"random_crop\": False,\n",
        "    \"random_flip\": True,\n",
        "    \"flip_horizontal\": False\n",
        "})\n",
        "\n",
        "# --- Hard keypoint mining ---\n",
        "cfg[\"optimization\"][\"hard_keypoint_mining\"][\"online_mining\"] = False\n",
        "cfg[\"optimization\"][\"hard_keypoint_mining\"][\"hard_to_easy_ratio\"] = 2.0\n",
        "cfg[\"optimization\"][\"hard_keypoint_mining\"][\"min_hard_keypoints\"] = 2\n",
        "cfg[\"optimization\"][\"hard_keypoint_mining\"][\"max_hard_keypoints\"] = None\n",
        "cfg[\"optimization\"][\"hard_keypoint_mining\"][\"loss_scale\"] = 5.0\n",
        "\n",
        "# --- Early stopping ---\n",
        "cfg[\"optimization\"][\"early_stopping\"][\"stop_training_on_plateau\"] = True\n",
        "cfg[\"optimization\"][\"early_stopping\"][\"plateau_min_delta\"] = 1e-8\n",
        "cfg[\"optimization\"][\"early_stopping\"][\"plateau_patience\"] = 10\n",
        "\n",
        "# ==============================================================\n",
        "# 💾 4️⃣ OUTPUTS CONFIGURATION\n",
        "# ==============================================================\n",
        "\n",
        "run_id = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "\n",
        "cfg[\"outputs\"][\"save_outputs\"] = True\n",
        "cfg[\"outputs\"][\"run_name_prefix\"] = f\"{MODEL_NAME}_{run_id}\"\n",
        "cfg[\"outputs\"][\"run_name_suffix\"] = \".single_instance\"\n",
        "cfg[\"outputs\"][\"runs_folder\"] = \"models\"\n",
        "cfg[\"outputs\"][\"tags\"] = EXPERIMENT_TAGS\n",
        "\n",
        "cfg[\"outputs\"][\"save_visualizations\"] = True\n",
        "cfg[\"outputs\"][\"keep_viz_images\"] = False\n",
        "cfg[\"outputs\"][\"zip_outputs\"] = False\n",
        "cfg[\"outputs\"][\"log_to_csv\"] = True\n",
        "\n",
        "# --- Checkpointing ---\n",
        "cfg[\"outputs\"][\"checkpointing\"][\"initial_model\"] = False\n",
        "cfg[\"outputs\"][\"checkpointing\"][\"best_model\"] = True\n",
        "cfg[\"outputs\"][\"checkpointing\"][\"every_epoch\"] = False\n",
        "cfg[\"outputs\"][\"checkpointing\"][\"latest_model\"] = False\n",
        "cfg[\"outputs\"][\"checkpointing\"][\"final_model\"] = False\n",
        "\n",
        "# --- TensorBoard ---\n",
        "cfg[\"outputs\"][\"tensorboard\"][\"write_logs\"] = True\n",
        "cfg[\"outputs\"][\"tensorboard\"][\"loss_frequency\"] = \"epoch\"\n",
        "cfg[\"outputs\"][\"tensorboard\"][\"architecture_graph\"] = False\n",
        "cfg[\"outputs\"][\"tensorboard\"][\"profile_graph\"] = False\n",
        "cfg[\"outputs\"][\"tensorboard\"][\"visualizations\"] = True\n",
        "\n",
        "# --- ZMQ (usually leave off) ---\n",
        "cfg[\"outputs\"][\"zmq\"][\"subscribe_to_controller\"] = False\n",
        "cfg[\"outputs\"][\"zmq\"][\"controller_address\"] = \"tcp://127.0.0.1:9000\"\n",
        "cfg[\"outputs\"][\"zmq\"][\"controller_polling_timeout\"] = 10\n",
        "cfg[\"outputs\"][\"zmq\"][\"publish_updates\"] = False\n",
        "cfg[\"outputs\"][\"zmq\"][\"publish_address\"] = \"tcp://127.0.0.1:9001\"\n",
        "\n",
        "# ==============================================================\n",
        "# ✅ SAVE CONFIGURATION + SUMMARY\n",
        "# ==============================================================\n",
        "\n",
        "with open(CONFIG_PATH, \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "print(\"✅ Saved all configuration changes to single_instance.json\\n\")\n",
        "\n",
        "print(\"📋 CONFIG SUMMARY:\")\n",
        "print(f\" Model backbone: {model_type.upper()}\")\n",
        "print(f\" Epochs: {cfg['optimization']['epochs']}\")\n",
        "print(f\" Batch size: {cfg['optimization']['batch_size']}\")\n",
        "print(f\" Learning rate: {cfg['optimization']['initial_learning_rate']}\")\n",
        "print(f\" Validation fraction: {cfg['data']['labels']['validation_fraction']}\")\n",
        "print(f\" Run name: {cfg['outputs']['run_name_prefix']}\")\n",
        "print(f\" Save folder: {cfg['outputs']['runs_folder']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zG9Kt3NlNX4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "===============================================================================\n",
        "  SLEAP QUICK CONFIGURATION SCRIPT\n",
        "===============================================================================\n",
        "\n",
        "Description:\n",
        "    This lightweight script is designed for daily workflow use — to quickly\n",
        "    update key hyperparameters for single-instance (single-animal) training in\n",
        "    SLEAP without modifying the full configuration structure.\n",
        "\n",
        "Purpose:\n",
        "    Ideal for changing frequently tuned parameters like:\n",
        "      - Batch size\n",
        "      - Epochs\n",
        "      - Learning rate\n",
        "      - Optimizer type\n",
        "      - UNet filters / stride\n",
        "      - Augmentation intensity\n",
        "      - Run naming and output folder\n",
        "\n",
        "Usage:\n",
        "    1. Adjust any of the editable parameters below\n",
        "    2️. Run the script in Google Colab before training\n",
        "    3️. Train your model with:\n",
        "        !sleap-train single_instance.json colab.slp\n",
        "\n",
        "Output:\n",
        "    - Updates and saves the existing single_instance.json file\n",
        "    - Automatically assigns a new run name with timestamp\n",
        "    - (Optional) Appends configuration details to training_log.txt for tracking\n",
        "\n",
        "Recommendation:\n",
        "     Use this script for *routine experiments* and the full master script for\n",
        "    *architecture changes* or complete reconfiguration.\n",
        "\n",
        "Author: Pedro Vasques + Chat GPT-5\n",
        "Version: Fast experimental workflow template\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# === EXPERIMENT SETTINGS ===\n",
        "MODEL_NAME = \"unet_fly_v1_\"     # change this for each new model run\n",
        "EXPERIMENT_TAGS = [\"drosophila_single\"]  # add tags for clarity if needed\n",
        "\n",
        "# === PATHS ===\n",
        "CONFIG_PATH = \"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/single_instance.json\"\n",
        "LABELS_PATH = \"/content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/colab.slp\"\n",
        "\n",
        "# === LOAD CONFIG ===\n",
        "with open(CONFIG_PATH) as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "# === USER SETTINGS ===\n",
        "# ---- General training ----\n",
        "cfg[\"optimization\"][\"batch_size\"] = 4            # number of images per batch\n",
        "cfg[\"optimization\"][\"epochs\"] = 200              # max epochs\n",
        "cfg[\"optimization\"][\"initial_learning_rate\"] = 1e-4\n",
        "cfg[\"optimization\"][\"optimizer\"] = \"adam\"        # or \"sgd\"\n",
        "cfg[\"data\"][\"labels\"][\"validation_fraction\"] = 0.1\n",
        "\n",
        "# ---- Model architecture ----\n",
        "cfg[\"model\"][\"backbone\"][\"unet\"][\"filters\"] = 32\n",
        "cfg[\"model\"][\"backbone\"][\"unet\"][\"output_stride\"] = 4   # (2 for finer precision)\n",
        "cfg[\"model\"][\"heads\"][\"single_instance\"][\"sigma\"] = 2.5\n",
        "\n",
        "# ---- Augmentations ----\n",
        "aug = cfg[\"optimization\"][\"augmentation_config\"]\n",
        "aug[\"rotate\"] = True\n",
        "aug[\"rotation_min_angle\"] = -15\n",
        "aug[\"rotation_max_angle\"] = 15\n",
        "aug[\"scale\"] = True\n",
        "aug[\"scale_min\"] = 0.9\n",
        "aug[\"scale_max\"] = 1.1\n",
        "aug[\"brightness\"] = True\n",
        "aug[\"contrast\"] = True\n",
        "aug[\"flip_horizontal\"] = False  # usually False for asymmetric animals\n",
        "\n",
        "# ---- Label path (always keep correct) ----\n",
        "cfg[\"data\"][\"labels\"][\"training_labels\"] = LABELS_PATH\n",
        "\n",
        "# ---- Output naming ----\n",
        "run_id = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "cfg[\"outputs\"][\"run_name_prefix\"] = f\"{MODEL_NAME}_{run_id}\"\n",
        "cfg[\"outputs\"][\"run_name_suffix\"] = \".single_instance\"\n",
        "cfg[\"outputs\"][\"runs_folder\"] = \"models\"\n",
        "cfg[\"outputs\"][\"tags\"] = EXPERIMENT_TAGS\n",
        "print(f\"✅ Updated configuration for run: {cfg['outputs']['run_name_prefix']}\")\n",
        "\n",
        "# === SAVE CONFIG ===\n",
        "with open(CONFIG_PATH, \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "print(f\"✅ Saved changes to {CONFIG_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSZoN4EbKBAm",
        "outputId": "e46e8090-7ba7-40b1-8d91-c016df2f2b33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated configuration for run: unet_fly_v1__251015_095020\n",
            "✅ Saved changes to /content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/single_instance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING COMAND"
      ],
      "metadata": {
        "id": "DlnD90v8S7No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sleap-train single_instance.json colab.slp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgHSBtJBHlkc",
        "outputId": "0b871dbd-01a7-4d18-df87-bcc65fcb9de9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:sleap.legacy_cli_adaptors:Started training at: 2025-10-15 09:07:23.814029\n",
            "2025-10-15 09:07:23 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:216 | Creating train-val split...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:261 | # Train Labeled frames: 414\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:262 | # Val Labeled frames: 46\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:setup_config:512 | Setting up config...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:_verify_model_input_channels:417 | Updating backbone in_channels to 3 based on the input image channels.\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:849 | Setting up for training...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:_setup_model_ckpt_dir:575 | Setting up model ckpt dir: `models/unet_fly_v1`...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:864 | Setting up visualization train and val datasets...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:868 | Setting up Trainer...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:_setup_loggers_callbacks:647 | Setting up callbacks and loggers...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:897 | Trainer devices: auto\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:950 | Training on 1 device(s)\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:951 | Training on cuda:0 accelerator\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:955 | Setting up lightning module for single_instance model...\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:959 | Backbone model: UNet(\n",
            "  (encoders): ModuleList(\n",
            "    (0): Encoder(\n",
            "      (encoder_stack): ModuleList(\n",
            "        (0): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc0_conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act0_relu): ReLU()\n",
            "            (stack0_enc0_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc1_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc1_conv0): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act0_relu): ReLU()\n",
            "            (stack0_enc1_conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc2_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc2_conv0): Conv2d(48, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act0_relu): ReLU()\n",
            "            (stack0_enc2_conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (3): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc3_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc3_conv0): Conv2d(72, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act0_relu): ReLU()\n",
            "            (stack0_enc3_conv1): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (4): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc4_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc4_conv0): Conv2d(108, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act0_relu): ReLU()\n",
            "            (stack0_enc4_conv1): Conv2d(162, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (stack0_enc5_last_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoders): ModuleList(\n",
            "    (0): Decoder(\n",
            "      (decoder_stack): ModuleList(\n",
            "        (0): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec0_s32_to_s16_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0): Conv2d(405, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1): Conv2d(162, 162, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec1_s16_to_s8_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0): Conv2d(270, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec2_s8_to_s4_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0): Conv2d(180, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (middle_blocks): ModuleList(\n",
            "    (0): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc6_middle_expand_conv0): Conv2d(162, 243, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc6_middle_expand_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc7_middle_contract_conv0): Conv2d(243, 243, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc7_middle_contract_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:960 | Head model: ModuleList(\n",
            "  (0): Sequential(\n",
            "    (SingleInstanceConfmapsHead): Sequential(\n",
            "      (0): Conv2d(72, 9, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:962 | Total model parameters: 2936824\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:967 | Input image shape: torch.Size([1, 3, 192, 704])\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:1021 | Finished trainer set up. [0.5s]\n",
            "2025-10-15 09:07:24 | INFO | sleap_nn.training.model_trainer:train:1024 | Starting training loop...\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /content/drive/My Drive/sleap/colab/CantonS_unamp_Fly1.3/models/unet_fly_v1 exists and is not empty.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 2.9 M  | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "2.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.9 M     Total params\n",
            "11.747    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 2.9 M  | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "2.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.9 M     Total params\n",
            "11.747    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('learning_rate', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:01<00:00,  1.89it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0:   0% 0/200 [00:00<?, ?it/s]       /usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('head1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('thorax1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('abdomen1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0: 100% 200/200 [00:44<00:00,  4.51it/s, head1_step=0.00229, thorax1_step=0.0023, abdomen1_step=0.0023, forelegR1_step=0.00174, forelegL1_step=0.00116, midlegR1_step=0.000585, midlegL1_step=0.00173, hindlegR1_step=0.00173, hindlegL1_step=0.000151, train_loss_step=0.00156]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 12/12 [00:01<00:00, 10.71it/s]\u001b[A\n",
            "Epoch 0: 100% 200/200 [00:46<00:00,  4.32it/s, head1_step=0.00229, thorax1_step=0.0023, abdomen1_step=0.0023, forelegR1_step=0.00174, forelegL1_step=0.00116, midlegR1_step=0.000585, midlegL1_step=0.00173, hindlegR1_step=0.00173, hindlegL1_step=0.000151, train_loss_step=0.00156, learning_rate_step=0.0001, val_loss_step=0.0016, learning_rate_epoch=0.0001, val_loss_epoch=0.00156, head1_epoch=0.00233, thorax1_epoch=0.00279, abdomen1_epoch=0.00279, forelegR1_epoch=0.00175, forelegL1_epoch=0.00139, midlegR1_epoch=0.00134, midlegL1_epoch=0.00135, hindlegR1_epoch=0.00102, hindlegL1_epoch=0.000916, train_loss_epoch=0.00174]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 1: 100% 200/200 [00:45<00:00,  4.42it/s, head1_step=0.00229, thorax1_step=0.0023, abdomen1_step=0.0023, forelegR1_step=0.00115, forelegL1_step=0.00173, midlegR1_step=0.00209, midlegL1_step=0.000583, hindlegR1_step=3.12e-6, hindlegL1_step=0.00116, train_loss_step=0.00151, learning_rate_step=0.0001, val_loss_step=0.0016, learning_rate_epoch=0.0001, val_loss_epoch=0.00156, head1_epoch=0.00233, thorax1_epoch=0.00279, abdomen1_epoch=0.00279, forelegR1_epoch=0.00175, forelegL1_epoch=0.00139, midlegR1_epoch=0.00134, midlegL1_epoch=0.00135, hindlegR1_epoch=0.00102, hindlegL1_epoch=0.000916, train_loss_epoch=0.00174] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 12/12 [00:01<00:00, 10.97it/s]\u001b[A\n",
            "Epoch 2: 100% 200/200 [00:45<00:00,  4.37it/s, head1_step=0.0023, thorax1_step=0.00231, abdomen1_step=0.0023, forelegR1_step=0.00101, forelegL1_step=0.00173, midlegR1_step=0.00124, midlegL1_step=0.000579, hindlegR1_step=0.000579, hindlegL1_step=0.000583, train_loss_step=0.0014, learning_rate_step=0.0001, val_loss_step=0.00159, learning_rate_epoch=0.0001, val_loss_epoch=0.00155, head1_epoch=0.00229, thorax1_epoch=0.00229, abdomen1_epoch=0.00228, forelegR1_epoch=0.0013, forelegL1_epoch=0.0013, midlegR1_epoch=0.00123, midlegL1_epoch=0.00119, hindlegR1_epoch=0.00102, hindlegL1_epoch=0.000727, train_loss_epoch=0.00151]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 12/12 [00:01<00:00, 11.31it/s]\u001b[A\n",
            "Epoch 3: 100% 200/200 [00:45<00:00,  4.42it/s, head1_step=0.00228, thorax1_step=0.00229, abdomen1_step=0.0023, forelegR1_step=0.000588, forelegL1_step=0.00172, midlegR1_step=0.00113, midlegL1_step=0.00112, hindlegR1_step=0.00115, hindlegL1_step=0.00058, train_loss_step=0.00146, learning_rate_step=0.0001, val_loss_step=0.00159, learning_rate_epoch=0.0001, val_loss_epoch=0.00155, head1_epoch=0.00228, thorax1_epoch=0.00227, abdomen1_epoch=0.00227, forelegR1_epoch=0.00127, forelegL1_epoch=0.00131, midlegR1_epoch=0.00125, midlegL1_epoch=0.00119, hindlegR1_epoch=0.00101, hindlegL1_epoch=0.000747, train_loss_epoch=0.00151]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 12/12 [00:01<00:00, 10.88it/s]\u001b[A\n",
            "Epoch 4:  70% 140/200 [00:30<00:13,  4.54it/s, head1_step=0.00227, thorax1_step=0.00228, abdomen1_step=0.00228, forelegR1_step=0.00229, forelegL1_step=1.29e-5, midlegR1_step=0.00115, midlegL1_step=0.00227, hindlegR1_step=0.00172, hindlegL1_step=3.66e-6, train_loss_step=0.00159, learning_rate_step=0.0001, val_loss_step=0.00159, learning_rate_epoch=0.0001, val_loss_epoch=0.00155, head1_epoch=0.00228, thorax1_epoch=0.00228, abdomen1_epoch=0.00227, forelegR1_epoch=0.0013, forelegL1_epoch=0.00128, midlegR1_epoch=0.00123, midlegL1_epoch=0.00118, hindlegR1_epoch=0.00102, hindlegL1_epoch=0.000714, train_loss_epoch=0.00151]INFO: \n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "INFO:lightning.pytorch.utilities.rank_zero:\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
            "2025-10-15 09:11:07 | INFO | sleap_nn.training.model_trainer:train:1037 | Finished training loop. [3.7 min]\n",
            "2025-10-15 09:11:07 | INFO | sleap_nn.training.model_trainer:train:1064 | Deleting viz folder at models/unet_fly_v1/viz...\n",
            "Epoch 4:  70% 140/200 [00:31<00:13,  4.47it/s, head1_step=0.00227, thorax1_step=0.00228, abdomen1_step=0.00228, forelegR1_step=0.00229, forelegL1_step=1.29e-5, midlegR1_step=0.00115, midlegL1_step=0.00227, hindlegR1_step=0.00172, hindlegL1_step=3.66e-6, train_loss_step=0.00159, learning_rate_step=0.0001, val_loss_step=0.00159, learning_rate_epoch=0.0001, val_loss_epoch=0.00155, head1_epoch=0.00228, thorax1_epoch=0.00228, abdomen1_epoch=0.00227, forelegR1_epoch=0.0013, forelegL1_epoch=0.00128, midlegR1_epoch=0.00123, midlegL1_epoch=0.00118, hindlegR1_epoch=0.00102, hindlegL1_epoch=0.000714, train_loss_epoch=0.00151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "If instead of bottom-up you've chosen the top-down pipeline (with two training configs), you would need to invoke two separate training jobs in sequence:\n",
        "\n",
        "- `!sleap-train centroid.json colab.pkg.slp`\n",
        "- `!sleap-train centered_instance.json colab.pkg.slp`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "## Run inference to predict instances\n",
        "\n",
        "Once training finishes, you'll see a new directory (or two new directories for top-down training pipeline) containing all the model files SLEAP needs to use for inference.\n",
        "\n",
        "Here we'll use the created model files to run inference in two modes:\n",
        "\n",
        "- predicting instances in suggested frames from the exported .slp file\n",
        "\n",
        "- predicting and tracking instances in uploaded video\n",
        "\n",
        "You can also download the trained models for running inference from the SLEAP GUI on your computer (or anywhere else).\n",
        "\n",
        "### Predicting instances in suggested frames\n",
        "This mode of predicting instances is useful for accelerating the manual labeling work; it allows you to get early predictions on suggested frames and merge them back into the project for faster labeling.\n",
        "\n",
        "Here we assume you've trained a bottom-up model and that the model files were written in directory named `colab_demo.bottomup`; later in this notebook we'll also show how to run inference with the pair of top-down models instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUszUYdj4ssi"
      },
      "outputs": [],
      "source": [
        "!sleap-track \\\n",
        "    -m colab_demo.bottomup \\\n",
        "    --only-suggested-frames \\\n",
        "    -o colab.predicted_suggestions.slp \\\n",
        "    colab.pkg.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1tMnCfL4ssi"
      },
      "source": [
        "Now, you can download the generated `colab.predicted_suggestions.slp` file and merge it into your labeling project (**File -> Merge into Project...** from the GUI) to get new predictions for your suggested frames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0-2bJCF4ssi"
      },
      "source": [
        "### Predicting and tracking instances in uploaded video\n",
        "Let's first upload the video we want to run inference on and name it `colab_demo.mp4`. (If your video is not named `colab_demo.mp4`, adjust the names below accordingly.)\n",
        "\n",
        "For this demo we'll just get predictions for the first 200 frames (or you can adjust the --frames parameter below or remove it to run on the whole video)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLtjtq9E1Znr"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.bottomup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, it will save the predictions in a file which can be opened in the GUI as a SLEAP project file. The file will be in the same directory as the video and the filename will be `{video filename}.predictions.slp`.\n",
        "\n",
        "Let's inspect the predictions file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfmNMSt-vS7"
      },
      "outputs": [],
      "source": [
        "!sleap-inspect colab_demo.mp4.predictions.slp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJ2kNBK-w6k"
      },
      "source": [
        "You can copy this file from your Google Drive to a local drive and open it in the SLEAP GUI app (or open it directly if you have your Google Drive mounted on your local machine). If the video is in the same directory as the predictions file, SLEAP will automatically find it; otherwise, you'll be prompted to locate the video (since the path to the video on your local machine will be different than the path to the video on Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-NoJOFvYHM"
      },
      "source": [
        "### Inference with top-down models\n",
        "\n",
        "If you trained the pair of models needed for top-down inference, you can call `sleap-track` with `-m path/to/model` for each model, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKnMc1qvim7"
      },
      "outputs": [],
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m colab_demo.centered_instance \\\n",
        "    -m colab_demo.centroid"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_and_inference_using_Google_Drive.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}