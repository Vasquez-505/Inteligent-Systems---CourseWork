{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasquez-505/Inteligent-Systems---CourseWork/blob/main/Project/Training_and_inference_using_Google_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaRFOIzzhZGD"
      },
      "source": [
        "# Training and inference on your own data using Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SLEAP Instalation\n"
      ],
      "metadata": {
        "id": "DmLUpI7Yz7gM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfnkxMtLcK3",
        "outputId": "4198e429-71bb-4544-ef0c-631cb8f69276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: sleap 1.5.1 does not provide the extra 'pypi'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m878.8/878.8 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m911.5/911.5 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.4/249.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.8/557.8 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.2/170.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.1/271.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.7/336.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nixio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            " SLEAP version: 1.5.1\n",
            " PyTorch version: 2.8.0+cu126\n",
            " CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]>=1.5.1\"\n",
        "\n",
        "# --- Sanity checks ---\n",
        "import sleap, torch\n",
        "print(\" SLEAP version:\", sleap.__version__)\n",
        "print(\" PyTorch version:\", torch.__version__)\n",
        "print(\" CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
        "!pip install -qqq \"sleap[pypi]==1.5.1\" sleap-io==0.5.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guty-iAksNRx",
        "outputId": "59fb83c1-2d47-417e-cc33-536aedda41f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: sleap 1.5.1 does not provide the extra 'pypi'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -qqq \"sleap-nn[torch-cuda-128]\""
      ],
      "metadata": {
        "id": "LKJP-LabvvUQ",
        "outputId": "dba5f506-8224-4193-8692-8f820ad77482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: sleap-nn 0.0.2 does not provide the extra 'torch-cuda-128'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check\n",
        "import sleap, sleap_io\n",
        "print(\"SLEAP:\", sleap.__version__)\n",
        "print(\"SLEAP-IO:\", sleap_io.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUyk67xxs1C5",
        "outputId": "85aadddc-58cf-4f62-c2fe-1663835af8db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLEAP: 1.5.1\n",
            "SLEAP-IO: 0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwpEwrxYdLMR"
      },
      "source": [
        "### Create and export the training job package\n",
        "A self-contained **training job package** contains a .slp file with labeled data and images which will be used for training, as well as .json training configuration file(s).\n",
        "\n",
        "A training job package can be exported in the SLEAP GUI fron the \"Run Training..\" dialog under the \"Predict\" menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApaDWxW4dLMS"
      },
      "source": [
        "### Upload training job package to Google Drive\n",
        "To be consistent with the examples in this notebook, name the SLEAP project `colab` and create a directory called `sleap` in the root of your Google Drive. Then upload the exported training job package `colab.slp.training_job.zip` into `sleap` directory.\n",
        "\n",
        "If you place your training pckage somewhere else, or name it differently, adjust the paths/filenames/parameters below accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBWjF4jpMG2N",
        "outputId": "e767af69-aeeb-4389-8fb9-125819e21cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umui-gI2rBz",
        "outputId": "558e04c2-087e-46fa-9042-08c86dfb6e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "colab.pkg.slp\t\t    inference-script.sh  single_instance.yaml\n",
            "colab.slp.training_job.zip  jobs.yaml\t\t train-script.sh\n",
            "fly1.2.mp4\t\t    models\n",
            "'11A-TOTAL questions profession.gdoc'\n",
            "'30s video - AI.mp4'\n",
            " 6FE1BFFC-0E21-430C-AB64-2B7DF4699F24.png\n",
            " 90BF88A5-D6B4-4385-940B-3BDB999E2F71.png\n",
            "'Boletim de inscrição editável do ensino Secundário a34839_signed.gdoc'\n",
            "'Boletim de inscrição editável do ensino Secundário a34839_signed.pdf'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Comprovativo.pdf\n",
            "'Curriculum Vitae.pdf'\n",
            "'ficha funções af(x).gdoc'\n",
            "'FINAL PORTA-CONTENTORES.gdoc'\n",
            "'FINAL PORTA-CONTENTORES.pdf'\n",
            "'Floresta Mediterrânea.pptx'\n",
            "'OMG! I got 19.txt'\n",
            " sleap\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# After uploading and unziping the training package run this to confirm the files uploaded are being seen\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/sleap\")\n",
        "!ls\n",
        "!ls /content/drive/MyDrive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MASTER Config Trainer Update"
      ],
      "metadata": {
        "id": "qJyxK0Ts1s_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === MASTER CONFIG UPDATER (no training) ===\n",
        "# Purpose:\n",
        "#   Automates configuration updates for SLEAP single-instance training.\n",
        "#   Edits:\n",
        "#     - single_instance.yaml : main training configuration\n",
        "#     - jobs.yaml            : job scheduler or metadata config\n",
        "#     - train-script.sh      : runnable shell script for training execution\n",
        "#   Ensures consistent naming and directory structure for reproducibility.\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "import os, yaml, datetime, pathlib\n",
        "\n",
        "# ------------------------------\n",
        "# PICK YOUR RUN / MODEL NAME HERE\n",
        "# ------------------------------\n",
        "RUN_NAME = \"drosophila_unet_32_\" + datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "LABELS_PATH = \"colab.pkg.slp\"          # Name of your slp file\n",
        "# Define where checkpoints should be saved\n",
        "EXPLICIT_CKPT_DIR = f\"models/{RUN_NAME}\"\n",
        "\n",
        "# Prevent double-nesting of model directories\n",
        "# (SLEAP already creates {ckpt_dir}/{run_name}/... internally)\n",
        "if RUN_NAME in EXPLICIT_CKPT_DIR:\n",
        "    CKPT_DIR = \"models\"\n",
        "else:\n",
        "    CKPT_DIR = EXPLICIT_CKPT_DIR\n",
        "\n",
        "\n",
        "SINGLE_INSTANCE_YAML = \"single_instance.yaml\"\n",
        "JOBS_YAML = \"jobs.yaml\"\n",
        "TRAIN_SH = \"train-script.sh\"\n",
        "\n",
        "# ------------------------------\n",
        "# FULL PARAMETER BLOCKS (edit anything)\n",
        "# ------------------------------\n",
        "\n",
        "DATA_CONFIG = {\n",
        "    \"train_labels_path\": [LABELS_PATH],\n",
        "    \"val_labels_path\": None,\n",
        "    \"validation_fraction\": 0.1,\n",
        "    \"test_file_path\": None,\n",
        "    \"provider\": \"LabelsReader\",\n",
        "    \"user_instances_only\": True,\n",
        "    \"data_pipeline_fw\": \"torch_dataset\",\n",
        "    \"cache_img_path\": None,\n",
        "    \"use_existing_imgs\": False,\n",
        "    \"delete_cache_imgs_after_training\": True,\n",
        "    \"preprocessing\": {\n",
        "        \"ensure_rgb\": True,            # set True if your images are RGB\n",
        "        \"ensure_grayscale\": False,      # set True if you force grayscale\n",
        "        \"max_height\": None,\n",
        "        \"max_width\": None,\n",
        "        \"scale\": 1.0,                   # <- CRITICAL input scaling\n",
        "        \"crop_size\": None,              # or [H, W]\n",
        "        \"min_crop_size\": 100,\n",
        "    },\n",
        "    \"use_augmentations_train\": False,\n",
        "    \"augmentation_config\": {\n",
        "        \"intensity\": {\n",
        "            \"uniform_noise_min\": 0.0,\n",
        "            \"uniform_noise_max\": 1.0,\n",
        "            \"uniform_noise_p\": 0.0,\n",
        "            \"gaussian_noise_mean\": 5.0,\n",
        "            \"gaussian_noise_std\": 0.0,\n",
        "            \"gaussian_noise_p\": 0.0,\n",
        "            \"contrast_min\": 0.5,\n",
        "            \"contrast_max\": 1.75,\n",
        "            \"contrast_p\": 0.0,\n",
        "            \"brightness_min\": 0.0,\n",
        "            \"brightness_max\": 2.0,\n",
        "            \"brightness_p\": 0.0,\n",
        "        },\n",
        "        \"geometric\": {\n",
        "            \"rotation_min\": -15.0,\n",
        "            \"rotation_max\": 15.0,\n",
        "            \"scale_min\": 0.9,\n",
        "            \"scale_max\": 1.1,\n",
        "            \"translate_width\": 0.0,\n",
        "            \"translate_height\": 0.0,\n",
        "            \"affine_p\": 1.0,\n",
        "            \"erase_scale_min\": 0.0001,\n",
        "            \"erase_scale_max\": 0.01,\n",
        "            \"erase_ratio_min\": 1.0,\n",
        "            \"erase_ratio_max\": 1.0,\n",
        "            \"erase_p\": 0.0,\n",
        "            \"mixup_lambda_min\": 0.01,\n",
        "            \"mixup_lambda_max\": 0.05,\n",
        "            \"mixup_p\": 0.0,\n",
        "        },\n",
        "    },\n",
        "    \"skeletons\": None,\n",
        "}\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"init_weights\": \"default\",\n",
        "    \"pretrained_backbone_weights\": None,\n",
        "    \"pretrained_head_weights\": None,\n",
        "    \"backbone_config\": {\n",
        "        \"unet\": {\n",
        "            \"in_channels\": 3,      # 1 for grayscale, 3 for RGB\n",
        "            \"kernel_size\": 3,\n",
        "            \"filters\": 64,\n",
        "            \"filters_rate\": 1.5,\n",
        "            \"max_stride\": 32,\n",
        "            \"stem_stride\": None,\n",
        "            \"middle_block\": True,\n",
        "            \"up_interpolate\": True,\n",
        "            \"stacks\": 1,\n",
        "            \"convs_per_block\": 2,\n",
        "            \"output_stride\": 4,\n",
        "        },\n",
        "        \"convnext\": None,\n",
        "        \"swint\": None,\n",
        "    },\n",
        "    \"head_configs\": {\n",
        "        \"single_instance\": {\n",
        "            \"confmaps\": {\n",
        "                \"part_names\": None,   # auto from labels if None\n",
        "                \"sigma\": 2.5,\n",
        "                \"output_stride\": 4,\n",
        "            }\n",
        "        },\n",
        "        \"centroid\": None,\n",
        "        \"centered_instance\": None,\n",
        "        \"bottomup\": None,\n",
        "        \"multi_class_bottomup\": None,\n",
        "        \"multi_class_topdown\": None,\n",
        "    },\n",
        "    \"total_params\": None,\n",
        "}\n",
        "\n",
        "TRAINER_CONFIG = {\n",
        "    \"train_data_loader\": {\"batch_size\": 6, \"shuffle\": False, \"num_workers\": 0},\n",
        "    \"val_data_loader\": {\"batch_size\": 6, \"shuffle\": False, \"num_workers\": 0},\n",
        "    \"model_ckpt\": {\"save_top_k\": 1, \"save_last\": False},\n",
        "    \"trainer_devices\": None,              # 'auto' or explicit list\n",
        "    \"trainer_device_indices\": None,\n",
        "    \"trainer_accelerator\": \"auto\",\n",
        "    \"profiler\": None,\n",
        "    \"trainer_strategy\": \"auto\",\n",
        "    \"enable_progress_bar\": True,\n",
        "    \"min_train_steps_per_epoch\": 200,\n",
        "    \"train_steps_per_epoch\": None,\n",
        "    \"visualize_preds_during_training\": True,\n",
        "    \"keep_viz\": False,\n",
        "    \"max_epochs\": 200,\n",
        "    \"seed\": 42,\n",
        "    \"use_wandb\": False,\n",
        "    \"save_ckpt\": True,\n",
        "    \"ckpt_dir\": CKPT_DIR,\n",
        "    \"run_name\": RUN_NAME,\n",
        "    \"resume_ckpt_path\": None,\n",
        "    \"wandb\": {\n",
        "        \"entity\": \"\",\n",
        "        \"project\": \"\",\n",
        "        \"name\": \"\",\n",
        "        \"save_viz_imgs_wandb\": False,\n",
        "        \"api_key\": \"\",\n",
        "        \"wandb_mode\": None,\n",
        "        \"prv_runid\": \"\",\n",
        "        \"group\": \"\",\n",
        "        \"current_run_id\": None,\n",
        "    },\n",
        "    \"optimizer_name\": \"Adam\",\n",
        "    \"optimizer\": {\"lr\": 1e-4, \"amsgrad\": False},\n",
        "    \"lr_scheduler\": None,\n",
        "    \"early_stopping\": {\n",
        "        \"min_delta\": 1e-8,\n",
        "        \"patience\": 20,\n",
        "        \"stop_training_on_plateau\": True,\n",
        "    },\n",
        "    \"online_hard_keypoint_mining\": {\n",
        "        \"online_mining\": False,\n",
        "        \"hard_to_easy_ratio\": 2.0,\n",
        "        \"min_hard_keypoints\": 2,\n",
        "        \"max_hard_keypoints\": None,\n",
        "        \"loss_scale\": 5.0,\n",
        "    },\n",
        "    \"zmq\": {\n",
        "        \"controller_port\": 9000,\n",
        "        \"controller_polling_timeout\": 10,\n",
        "        \"publish_port\": 9001,\n",
        "    },\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# Helpers\n",
        "# ------------------------------\n",
        "def _ensure_keys(d, template):\n",
        "    \"\"\"Recursively ensure keys from template exist in dict d.\"\"\"\n",
        "    if d is None:\n",
        "        return template\n",
        "    for k, v in template.items():\n",
        "        if k not in d or d[k] is None:\n",
        "            d[k] = v\n",
        "        else:\n",
        "            if isinstance(v, dict):\n",
        "                d[k] = _ensure_keys(d.get(k, {}), v)\n",
        "    return d\n",
        "\n",
        "def _safe_update(d, updates):\n",
        "    \"\"\"Recursively update d with updates, preserving other keys.\"\"\"\n",
        "    for k, v in updates.items():\n",
        "        if isinstance(v, dict):\n",
        "            d[k] = _safe_update(d.get(k, {}) if isinstance(d.get(k), dict) else {}, v)\n",
        "        else:\n",
        "            d[k] = v\n",
        "    return d\n",
        "\n",
        "def _load_yaml(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def _save_yaml(path, data):\n",
        "    with open(path, \"w\") as f:\n",
        "        yaml.safe_dump(data, f, sort_keys=False)\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Update single_instance.yaml\n",
        "# ------------------------------\n",
        "si = _load_yaml(SINGLE_INSTANCE_YAML)\n",
        "\n",
        "# Ensure structure exists exactly as your schema\n",
        "si = _ensure_keys(si, {\n",
        "    \"data_config\": {},\n",
        "    \"model_config\": {},\n",
        "    \"trainer_config\": {},\n",
        "    \"name\": \"\",\n",
        "    \"description\": \"\",\n",
        "    \"sleap_nn_version\": si.get(\"sleap_nn_version\", \"0.0.2\"),\n",
        "    \"filename\": \"\",\n",
        "})\n",
        "\n",
        "# Merge updates\n",
        "si[\"data_config\"]      = _safe_update(si[\"data_config\"], DATA_CONFIG)\n",
        "si[\"model_config\"]     = _safe_update(si[\"model_config\"], MODEL_CONFIG)\n",
        "si[\"trainer_config\"]   = _safe_update(si[\"trainer_config\"], TRAINER_CONFIG)\n",
        "si[\"trainer_config\"][\"run_name\"] = RUN_NAME\n",
        "si[\"trainer_config\"][\"ckpt_dir\"] = CKPT_DIR\n",
        "\n",
        "# Save\n",
        "# Ensure model folder exists for cleanliness\n",
        "pathlib.Path(CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "_save_yaml = _save_yaml  # avoid accidental shadowing\n",
        "_save_yaml(SINGLE_INSTANCE_YAML, si)\n",
        "print(f\" Updated {SINGLE_INSTANCE_YAML} with run_name={RUN_NAME}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Update jobs.yaml (best effort; keeps structure)\n",
        "# ------------------------------\n",
        "if os.path.exists(JOBS_YAML):\n",
        "    jobs = _load_yaml(JOBS_YAML)\n",
        "\n",
        "    # Try common fields used by Colab templates; only update if present\n",
        "    # We keep your structure intact.\n",
        "    def set_if_exists(root, keys, value):\n",
        "        cur = root\n",
        "        for k in keys[:-1]:\n",
        "            if not isinstance(cur, dict) or k not in cur:\n",
        "                return\n",
        "            cur = cur[k]\n",
        "        if isinstance(cur, dict) and keys[-1] in cur:\n",
        "            cur[keys[-1]] = value\n",
        "\n",
        "    # Common spots we might find these\n",
        "    set_if_exists(jobs, [\"training_job\", \"trainer_config\", \"run_name\"], RUN_NAME)\n",
        "    set_if_exists(jobs, [\"training_job\", \"trainer_config\", \"ckpt_dir\"], CKPT_DIR)\n",
        "    set_if_exists(jobs, [\"training_job\", \"data_config\", \"train_labels_path\"], [LABELS_PATH])\n",
        "    set_if_exists(jobs, [\"training_job\", \"config_path\"], SINGLE_INSTANCE_YAML)\n",
        "\n",
        "    _save_yaml(JOBS_YAML, jobs)\n",
        "    print(f\" Updated {JOBS_YAML} (run_name, ckpt_dir, labels if present)\")\n",
        "else:\n",
        "    print(f\" {JOBS_YAML} not found — skipped (that’s fine).\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Update train-script.sh\n",
        "# ------------------------------\n",
        "train_script = f\"\"\"#!/bin/bash\n",
        "# Auto-generated: {RUN_NAME}\n",
        "echo \"Starting SLEAP training: {RUN_NAME}\"\n",
        "sleap-train {SINGLE_INSTANCE_YAML} {LABELS_PATH} --first-gpu\n",
        "\"\"\"\n",
        "with open(TRAIN_SH, \"w\") as f:\n",
        "    f.write(train_script)\n",
        "os.chmod(TRAIN_SH, 0o755)\n",
        "print(f\" Updated {TRAIN_SH}\")\n",
        "\n",
        "print(f\"\\n Ready. Model/run name: {RUN_NAME}\\nCheckpoints: {CKPT_DIR}\\nLabels: {LABELS_PATH}\")\n"
      ],
      "metadata": {
        "id": "LcOHBV0v4x-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290c0ec6-33f0-421a-922f-376c3d5b5c27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Updated single_instance.yaml with run_name=drosophila_unet_64_251020_093034\n",
            " Updated jobs.yaml (run_name, ckpt_dir, labels if present)\n",
            " Updated train-script.sh\n",
            "\n",
            " Ready. Model/run name: drosophila_unet_64_251020_093034\n",
            "Checkpoints: models\n",
            "Labels: colab.pkg.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "Let's train a model with the training profile (.json file) and the project data (.slp file) you have exported from SLEAP.\n",
        "\n",
        "\n",
        "### Note on training profiles\n",
        "Depending on the pipeline you chose in the training dialog, the config filename(s) will be:\n",
        "\n",
        "- for a **bottom-up** pipeline approach: `multi_instance.json` (this is the pipeline we assume here),\n",
        "\n",
        "- for a **top-down** pipeline, you'll have a different profile for each of the models: `centroid.json` and `centered_instance.json`,\n",
        "\n",
        "- for a **single animal** pipeline: `single_instance.json`.\n",
        "\n",
        "\n",
        "### Note on training process\n",
        "When you start training, you'll first see the training parameters and then the training and validation loss for each training epoch.\n",
        "\n",
        "As soon as you're satisfied with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference.\n",
        "\n",
        "If you don't stop training, it will run for 200 epochs or until validation loss fails to improve for some number of epochs (controlled by the early_stopping fields in the training profile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QKf6qzMqNBUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863dfc0d-2045-48c7-8f64-0bd15c0cf071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:sleap.legacy_cli_adaptors:Started training at: 2025-10-20 09:30:50.521809\n",
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n",
            "2025-10-20 09:30:50 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:216 | Creating train-val split...\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:261 | # Train Labeled frames: 407\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:_setup_train_val_labels:262 | # Val Labeled frames: 45\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:setup_config:512 | Setting up config...\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:train:849 | Setting up for training...\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:_setup_model_ckpt_dir:575 | Setting up model ckpt dir: `models/drosophila_unet_64_251020_093034`...\n",
            "2025-10-20 09:30:51 | INFO | sleap_nn.training.model_trainer:train:864 | Setting up visualization train and val datasets...\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:868 | Setting up Trainer...\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:_setup_loggers_callbacks:647 | Setting up callbacks and loggers...\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:897 | Trainer devices: auto\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:950 | Training on 1 device(s)\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:951 | Training on cuda:0 accelerator\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:955 | Setting up lightning module for single_instance model...\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:959 | Backbone model: UNet(\n",
            "  (encoders): ModuleList(\n",
            "    (0): Encoder(\n",
            "      (encoder_stack): ModuleList(\n",
            "        (0): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc0_conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act0_relu): ReLU()\n",
            "            (stack0_enc0_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc0_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc1_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc1_conv0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act0_relu): ReLU()\n",
            "            (stack0_enc1_conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc1_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc2_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc2_conv0): Conv2d(96, 144, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act0_relu): ReLU()\n",
            "            (stack0_enc2_conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc2_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (3): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc3_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc3_conv0): Conv2d(144, 216, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act0_relu): ReLU()\n",
            "            (stack0_enc3_conv1): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc3_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (4): SimpleConvBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_enc4_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "            (stack0_enc4_conv0): Conv2d(216, 324, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act0_relu): ReLU()\n",
            "            (stack0_enc4_conv1): Conv2d(324, 324, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_enc4_act1_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (5): Sequential(\n",
            "          (stack0_enc5_last_pool): MaxPool2dWithSamePadding(kernel_size=2, stride=2, padding=same, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoders): ModuleList(\n",
            "    (0): Decoder(\n",
            "      (decoder_stack): ModuleList(\n",
            "        (0): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec0_s32_to_s16_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0): Conv2d(810, 324, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1): Conv2d(324, 324, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec0_s32_to_s16_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec1_s16_to_s8_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0): Conv2d(540, 216, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec1_s16_to_s8_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (2): SimpleUpsamplingBlock(\n",
            "          (blocks): Sequential(\n",
            "            (stack0_dec2_s8_to_s4_interp_bilinear): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0): Conv2d(360, 144, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv0_act_relu): ReLU()\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "            (stack0_dec2_s8_to_s4_refine_conv1_act_relu): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (middle_blocks): ModuleList(\n",
            "    (0): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc6_middle_expand_conv0): Conv2d(324, 486, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc6_middle_expand_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): SimpleConvBlock(\n",
            "      (blocks): Sequential(\n",
            "        (stack0_enc7_middle_contract_conv0): Conv2d(486, 486, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "        (stack0_enc7_middle_contract_act0_relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:960 | Head model: ModuleList(\n",
            "  (0): Sequential(\n",
            "    (SingleInstanceConfmapsHead): Sequential(\n",
            "      (0): Conv2d(144, 9, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:962 | Total model parameters: 11740217\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:967 | Input image shape: torch.Size([1, 3, 192, 704])\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:1021 | Finished trainer set up. [0.8s]\n",
            "2025-10-20 09:30:52 | INFO | sleap_nn.training.model_trainer:train:1024 | Starting training loop...\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /content/drive/MyDrive/sleap/models/drosophila_unet_64_251020_093034 exists and is not empty.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 11.7 M | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "11.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.7 M    Total params\n",
            "46.961    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name                      | Type                         | Params | Mode \n",
            "-----------------------------------------------------------------------------------\n",
            "0 | model                     | Model                        | 11.7 M | train\n",
            "1 | single_instance_inf_layer | SingleInstanceInferenceModel | 0      | train\n",
            "-----------------------------------------------------------------------------------\n",
            "11.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.7 M    Total params\n",
            "46.961    Total estimated model params size (MB)\n",
            "80        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('learning_rate', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:00<00:00,  2.87it/s]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('val_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0:   0% 0/200 [00:00<?, ?it/s]       /usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('head1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('thorax1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('abdomen1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('forelegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('midlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegR1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('hindlegL1', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 0: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=0.000419, thorax1_step=0.00018, abdomen1_step=0.000383, forelegR1_step=0.000324, forelegL1_step=0.000881, midlegR1_step=0.000741, midlegL1_step=0.000249, hindlegR1_step=0.000903, hindlegL1_step=0.000859, train_loss_step=0.000549]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.01it/s]\u001b[A\n",
            "Epoch 0: 100% 200/200 [01:09<00:00,  2.87it/s, head1_step=0.000419, thorax1_step=0.00018, abdomen1_step=0.000383, forelegR1_step=0.000324, forelegL1_step=0.000881, midlegR1_step=0.000741, midlegL1_step=0.000249, hindlegR1_step=0.000903, hindlegL1_step=0.000859, train_loss_step=0.000549, learning_rate_step=0.0001, val_loss_step=0.000375, learning_rate_epoch=0.0001, val_loss_epoch=0.000385, head1_epoch=0.00079, thorax1_epoch=0.0008, abdomen1_epoch=0.000817, forelegR1_epoch=0.00101, forelegL1_epoch=0.00108, midlegR1_epoch=0.001, midlegL1_epoch=0.001, hindlegR1_epoch=0.00105, hindlegL1_epoch=0.000739, train_loss_epoch=0.000921]/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py:520: You called `self.log('train_time', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
            "Epoch 1: 100% 200/200 [01:08<00:00,  2.93it/s, head1_step=0.000159, thorax1_step=8.79e-5, abdomen1_step=8.52e-5, forelegR1_step=7.69e-5, forelegL1_step=0.000383, midlegR1_step=0.000182, midlegL1_step=0.000199, hindlegR1_step=0.000133, hindlegL1_step=0.000617, train_loss_step=0.000214, learning_rate_step=0.0001, val_loss_step=0.000375, learning_rate_epoch=0.0001, val_loss_epoch=0.000385, head1_epoch=0.00079, thorax1_epoch=0.0008, abdomen1_epoch=0.000817, forelegR1_epoch=0.00101, forelegL1_epoch=0.00108, midlegR1_epoch=0.001, midlegL1_epoch=0.001, hindlegR1_epoch=0.00105, hindlegL1_epoch=0.000739, train_loss_epoch=0.000921]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.88it/s]\u001b[A\n",
            "Epoch 2: 100% 200/200 [01:11<00:00,  2.79it/s, head1_step=9.48e-5, thorax1_step=9.45e-5, abdomen1_step=8.1e-5, forelegR1_step=0.000341, forelegL1_step=0.000518, midlegR1_step=0.000158, midlegL1_step=0.000109, hindlegR1_step=0.000221, hindlegL1_step=5.77e-5, train_loss_step=0.000186, learning_rate_step=0.0001, val_loss_step=0.000191, learning_rate_epoch=0.0001, val_loss_epoch=0.000214, head1_epoch=0.000165, thorax1_epoch=0.000127, abdomen1_epoch=0.000181, forelegR1_epoch=0.000327, forelegL1_epoch=0.000424, midlegR1_epoch=0.000238, midlegL1_epoch=0.000269, hindlegR1_epoch=0.000351, hindlegL1_epoch=0.000378, train_loss_epoch=0.000274]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.95it/s]\u001b[A\n",
            "Epoch 3: 100% 200/200 [01:12<00:00,  2.77it/s, head1_step=7.76e-5, thorax1_step=3.76e-5, abdomen1_step=8.1e-5, forelegR1_step=4.7e-5, forelegL1_step=3.43e-5, midlegR1_step=2.12e-5, midlegL1_step=6.59e-5, hindlegR1_step=0.00013, hindlegL1_step=2.43e-5, train_loss_step=5.77e-5, learning_rate_step=0.0001, val_loss_step=0.000192, learning_rate_epoch=0.0001, val_loss_epoch=0.000182, head1_epoch=0.000108, thorax1_epoch=9.73e-5, abdomen1_epoch=9.25e-5, forelegR1_epoch=0.000177, forelegL1_epoch=0.000198, midlegR1_epoch=0.000147, midlegL1_epoch=0.000168, hindlegR1_epoch=0.000199, hindlegL1_epoch=0.000242, train_loss_epoch=0.000159]       \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.82it/s]\u001b[A\n",
            "Epoch 4: 100% 200/200 [01:11<00:00,  2.79it/s, head1_step=5.44e-5, thorax1_step=4.46e-5, abdomen1_step=5.06e-5, forelegR1_step=1.89e-5, forelegL1_step=1.95e-5, midlegR1_step=1.39e-5, midlegL1_step=4.03e-5, hindlegR1_step=6.8e-5, hindlegL1_step=8.1e-5, train_loss_step=4.35e-5, learning_rate_step=0.0001, val_loss_step=0.000115, learning_rate_epoch=0.0001, val_loss_epoch=0.000134, head1_epoch=9.47e-5, thorax1_epoch=7.24e-5, abdomen1_epoch=8.49e-5, forelegR1_epoch=0.000125, forelegL1_epoch=0.00012, midlegR1_epoch=0.000105, midlegL1_epoch=0.000139, hindlegR1_epoch=0.000141, hindlegL1_epoch=0.000186, train_loss_epoch=0.000119]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.94it/s]\u001b[A\n",
            "Epoch 5: 100% 200/200 [01:12<00:00,  2.77it/s, head1_step=6.59e-5, thorax1_step=3.41e-5, abdomen1_step=0.00012, forelegR1_step=3.08e-5, forelegL1_step=9.77e-5, midlegR1_step=2.25e-5, midlegL1_step=0.000287, hindlegR1_step=4.92e-5, hindlegL1_step=7.71e-5, train_loss_step=8.71e-5, learning_rate_step=0.0001, val_loss_step=8.68e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000124, head1_epoch=8.21e-5, thorax1_epoch=6.17e-5, abdomen1_epoch=8.56e-5, forelegR1_epoch=9.6e-5, forelegL1_epoch=8.7e-5, midlegR1_epoch=8.03e-5, midlegL1_epoch=0.00013, hindlegR1_epoch=0.000117, hindlegL1_epoch=0.000146, train_loss_epoch=9.84e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.82it/s]\u001b[A\n",
            "Epoch 6: 100% 200/200 [01:12<00:00,  2.77it/s, head1_step=3.71e-5, thorax1_step=3.98e-5, abdomen1_step=8.14e-5, forelegR1_step=8.71e-5, forelegL1_step=1.36e-5, midlegR1_step=5.88e-5, midlegL1_step=0.000109, hindlegR1_step=5.22e-5, hindlegL1_step=1.49e-5, train_loss_step=5.49e-5, learning_rate_step=0.0001, val_loss_step=7.19e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000112, head1_epoch=6.57e-5, thorax1_epoch=5.2e-5, abdomen1_epoch=6.38e-5, forelegR1_epoch=7.33e-5, forelegL1_epoch=6.57e-5, midlegR1_epoch=5.78e-5, midlegL1_epoch=0.000119, hindlegR1_epoch=9.59e-5, hindlegL1_epoch=0.000126, train_loss_epoch=7.99e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.86it/s]\u001b[A\n",
            "Epoch 7: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=4.78e-5, thorax1_step=2.92e-5, abdomen1_step=5.14e-5, forelegR1_step=1.02e-5, forelegL1_step=5.99e-5, midlegR1_step=1.23e-5, midlegL1_step=9.4e-6, hindlegR1_step=1.51e-5, hindlegL1_step=1.06e-5, train_loss_step=2.73e-5, learning_rate_step=0.0001, val_loss_step=7.49e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000114, head1_epoch=6.06e-5, thorax1_epoch=4.73e-5, abdomen1_epoch=6.86e-5, forelegR1_epoch=5.97e-5, forelegL1_epoch=5.57e-5, midlegR1_epoch=4.68e-5, midlegL1_epoch=0.000118, hindlegR1_epoch=7.58e-5, hindlegL1_epoch=0.000116, train_loss_epoch=7.21e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.75it/s]\u001b[A\n",
            "Epoch 8: 100% 200/200 [01:12<00:00,  2.76it/s, head1_step=3.48e-5, thorax1_step=3.32e-5, abdomen1_step=5.69e-5, forelegR1_step=0.000104, forelegL1_step=3.47e-5, midlegR1_step=1.07e-5, midlegL1_step=1.45e-5, hindlegR1_step=1.07e-5, hindlegL1_step=4.49e-5, train_loss_step=3.82e-5, learning_rate_step=0.0001, val_loss_step=5.74e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000102, head1_epoch=5.87e-5, thorax1_epoch=4.46e-5, abdomen1_epoch=6.59e-5, forelegR1_epoch=5.06e-5, forelegL1_epoch=5.34e-5, midlegR1_epoch=4.22e-5, midlegL1_epoch=9.62e-5, hindlegR1_epoch=7.55e-5, hindlegL1_epoch=9.02e-5, train_loss_epoch=6.41e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.87it/s]\u001b[A\n",
            "Epoch 9: 100% 200/200 [01:11<00:00,  2.79it/s, head1_step=2.91e-5, thorax1_step=2.05e-5, abdomen1_step=5.43e-5, forelegR1_step=1.08e-5, forelegL1_step=2.26e-5, midlegR1_step=5.04e-6, midlegL1_step=2.25e-5, hindlegR1_step=5.4e-6, hindlegL1_step=1.35e-5, train_loss_step=2.04e-5, learning_rate_step=0.0001, val_loss_step=5.83e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.0001, head1_epoch=5.57e-5, thorax1_epoch=3.83e-5, abdomen1_epoch=5.03e-5, forelegR1_epoch=3.94e-5, forelegL1_epoch=4.86e-5, midlegR1_epoch=2.99e-5, midlegL1_epoch=7.62e-5, hindlegR1_epoch=5.98e-5, hindlegL1_epoch=6.23e-5, train_loss_epoch=5.12e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.88it/s]\u001b[A\n",
            "Epoch 10: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=6.18e-5, thorax1_step=2.25e-5, abdomen1_step=1.93e-5, forelegR1_step=1e-5, forelegL1_step=1.4e-5, midlegR1_step=4.98e-6, midlegL1_step=2.58e-5, hindlegR1_step=1.67e-5, hindlegL1_step=6.79e-5, train_loss_step=2.7e-5, learning_rate_step=0.0001, val_loss_step=9.43e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000114, head1_epoch=4.5e-5, thorax1_epoch=3.49e-5, abdomen1_epoch=4.86e-5, forelegR1_epoch=3.33e-5, forelegL1_epoch=3.96e-5, midlegR1_epoch=2.68e-5, midlegL1_epoch=7.39e-5, hindlegR1_epoch=4.8e-5, hindlegL1_epoch=5.63e-5, train_loss_epoch=4.52e-5]      \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.62it/s]\u001b[A\n",
            "Epoch 11: 100% 200/200 [01:08<00:00,  2.93it/s, head1_step=1.55e-5, thorax1_step=1.58e-5, abdomen1_step=4.43e-5, forelegR1_step=4.22e-5, forelegL1_step=9.8e-6, midlegR1_step=7.56e-6, midlegL1_step=1.15e-5, hindlegR1_step=7.05e-5, hindlegL1_step=3.02e-6, train_loss_step=2.45e-5, learning_rate_step=0.0001, val_loss_step=7e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=3.99e-5, thorax1_epoch=3.18e-5, abdomen1_epoch=4.19e-5, forelegR1_epoch=2.96e-5, forelegL1_epoch=3.48e-5, midlegR1_epoch=2.35e-5, midlegL1_epoch=5.31e-5, hindlegR1_epoch=4.13e-5, hindlegL1_epoch=3.77e-5, train_loss_epoch=3.71e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.00it/s]\u001b[A\n",
            "Epoch 12: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=5.77e-5, thorax1_step=2.43e-5, abdomen1_step=4.05e-5, forelegR1_step=2.23e-5, forelegL1_step=6.33e-6, midlegR1_step=1.53e-5, midlegL1_step=0.000208, hindlegR1_step=0.000104, hindlegL1_step=2.03e-5, train_loss_step=5.54e-5, learning_rate_step=0.0001, val_loss_step=6.69e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000107, head1_epoch=3.65e-5, thorax1_epoch=2.89e-5, abdomen1_epoch=3.66e-5, forelegR1_epoch=2.48e-5, forelegL1_epoch=2.5e-5, midlegR1_epoch=2.03e-5, midlegL1_epoch=4.14e-5, hindlegR1_epoch=2.92e-5, hindlegL1_epoch=2.7e-5, train_loss_epoch=3e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.05it/s]\u001b[A\n",
            "Epoch 13: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=4.42e-5, thorax1_step=2.4e-5, abdomen1_step=2.39e-5, forelegR1_step=9.64e-6, forelegL1_step=2.2e-5, midlegR1_step=5.12e-6, midlegL1_step=2.2e-5, hindlegR1_step=9.32e-5, hindlegL1_step=1.44e-5, train_loss_step=2.87e-5, learning_rate_step=0.0001, val_loss_step=7.41e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000108, head1_epoch=3.97e-5, thorax1_epoch=3.21e-5, abdomen1_epoch=3.95e-5, forelegR1_epoch=2.81e-5, forelegL1_epoch=2.73e-5, midlegR1_epoch=2.25e-5, midlegL1_epoch=5.5e-5, hindlegR1_epoch=3.14e-5, hindlegL1_epoch=4.26e-5, train_loss_epoch=3.53e-5]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.60it/s]\u001b[A\n",
            "Epoch 14: 100% 200/200 [01:08<00:00,  2.94it/s, head1_step=2.26e-5, thorax1_step=1.74e-5, abdomen1_step=2.48e-5, forelegR1_step=1.95e-5, forelegL1_step=6.09e-6, midlegR1_step=2.27e-6, midlegL1_step=7.39e-5, hindlegR1_step=2.22e-5, hindlegL1_step=3.14e-6, train_loss_step=2.13e-5, learning_rate_step=0.0001, val_loss_step=6.23e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=4.06e-5, thorax1_epoch=3.18e-5, abdomen1_epoch=4.36e-5, forelegR1_epoch=2.69e-5, forelegL1_epoch=3.42e-5, midlegR1_epoch=2.37e-5, midlegL1_epoch=5.53e-5, hindlegR1_epoch=3.59e-5, hindlegL1_epoch=4.38e-5, train_loss_epoch=3.73e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.37it/s]\u001b[A\n",
            "Epoch 15: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=1.9e-5, thorax1_step=1.53e-5, abdomen1_step=1.82e-5, forelegR1_step=0.00039, forelegL1_step=7.79e-6, midlegR1_step=6.58e-6, midlegL1_step=3.13e-6, hindlegR1_step=6.14e-6, hindlegL1_step=3.29e-6, train_loss_step=5.21e-5, learning_rate_step=0.0001, val_loss_step=5.75e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000107, head1_epoch=3.2e-5, thorax1_epoch=2.73e-5, abdomen1_epoch=3.3e-5, forelegR1_epoch=2.53e-5, forelegL1_epoch=1.97e-5, midlegR1_epoch=1.58e-5, midlegL1_epoch=3.27e-5, hindlegR1_epoch=2.2e-5, hindlegL1_epoch=2.07e-5, train_loss_epoch=2.54e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.78it/s]\u001b[A\n",
            "Epoch 16: 100% 200/200 [01:07<00:00,  2.94it/s, head1_step=3.97e-5, thorax1_step=2.01e-5, abdomen1_step=2.26e-5, forelegR1_step=2.57e-6, forelegL1_step=2.79e-6, midlegR1_step=3.71e-6, midlegL1_step=6.16e-6, hindlegR1_step=0.000245, hindlegL1_step=1.67e-6, train_loss_step=3.83e-5, learning_rate_step=0.0001, val_loss_step=5.61e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000109, head1_epoch=3.33e-5, thorax1_epoch=2.69e-5, abdomen1_epoch=3.12e-5, forelegR1_epoch=2.87e-5, forelegL1_epoch=2e-5, midlegR1_epoch=1.69e-5, midlegL1_epoch=3.83e-5, hindlegR1_epoch=2.41e-5, hindlegL1_epoch=1.72e-5, train_loss_epoch=2.63e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.84it/s]\u001b[A\n",
            "Epoch 17: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=2.79e-5, thorax1_step=2.59e-5, abdomen1_step=3.67e-5, forelegR1_step=1.06e-5, forelegL1_step=2.32e-5, midlegR1_step=0.00028, midlegL1_step=4.39e-6, hindlegR1_step=7.39e-6, hindlegL1_step=8.81e-6, train_loss_step=4.72e-5, learning_rate_step=0.0001, val_loss_step=7.11e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000122, head1_epoch=3.17e-5, thorax1_epoch=2.72e-5, abdomen1_epoch=3.02e-5, forelegR1_epoch=2.01e-5, forelegL1_epoch=1.79e-5, midlegR1_epoch=1.6e-5, midlegL1_epoch=3.13e-5, hindlegR1_epoch=1.88e-5, hindlegL1_epoch=1.46e-5, train_loss_epoch=2.31e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.89it/s]\u001b[A\n",
            "Epoch 18: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=4.21e-5, thorax1_step=2.21e-5, abdomen1_step=3.64e-5, forelegR1_step=4.28e-6, forelegL1_step=2.67e-5, midlegR1_step=1.47e-5, midlegL1_step=6.51e-6, hindlegR1_step=4.78e-6, hindlegL1_step=1.09e-5, train_loss_step=1.87e-5, learning_rate_step=0.0001, val_loss_step=0.000116, learning_rate_epoch=0.0001, val_loss_epoch=0.000122, head1_epoch=3.25e-5, thorax1_epoch=2.75e-5, abdomen1_epoch=3.02e-5, forelegR1_epoch=2.03e-5, forelegL1_epoch=1.63e-5, midlegR1_epoch=1.35e-5, midlegL1_epoch=2.68e-5, hindlegR1_epoch=1.25e-5, hindlegL1_epoch=1.36e-5, train_loss_epoch=2.15e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.95it/s]\u001b[A\n",
            "Epoch 19: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=8.65e-5, thorax1_step=2.94e-5, abdomen1_step=2.45e-5, forelegR1_step=4.54e-5, forelegL1_step=7.12e-5, midlegR1_step=3.41e-6, midlegL1_step=3.19e-5, hindlegR1_step=4.29e-6, hindlegL1_step=6.25e-6, train_loss_step=3.37e-5, learning_rate_step=0.0001, val_loss_step=7.08e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000124, head1_epoch=3.84e-5, thorax1_epoch=3.01e-5, abdomen1_epoch=3.74e-5, forelegR1_epoch=2.58e-5, forelegL1_epoch=2.31e-5, midlegR1_epoch=2.29e-5, midlegL1_epoch=3.43e-5, hindlegR1_epoch=2.99e-5, hindlegL1_epoch=2e-5, train_loss_epoch=2.91e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.86it/s]\u001b[A\n",
            "Epoch 20: 100% 200/200 [01:11<00:00,  2.80it/s, head1_step=7.4e-5, thorax1_step=2.81e-5, abdomen1_step=2.88e-5, forelegR1_step=9.74e-6, forelegL1_step=8.37e-6, midlegR1_step=1.24e-5, midlegL1_step=1.49e-5, hindlegR1_step=1.25e-5, hindlegL1_step=1.03e-5, train_loss_step=2.21e-5, learning_rate_step=0.0001, val_loss_step=7.51e-5, learning_rate_epoch=0.0001, val_loss_epoch=9.87e-5, head1_epoch=3.71e-5, thorax1_epoch=3.22e-5, abdomen1_epoch=3.2e-5, forelegR1_epoch=2.02e-5, forelegL1_epoch=2.26e-5, midlegR1_epoch=1.53e-5, midlegL1_epoch=3.45e-5, hindlegR1_epoch=1.48e-5, hindlegL1_epoch=1.59e-5, train_loss_epoch=2.49e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.04it/s]\u001b[A\n",
            "Epoch 21: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=3.55e-5, thorax1_step=3.92e-5, abdomen1_step=1.43e-5, forelegR1_step=4.9e-6, forelegL1_step=1.28e-5, midlegR1_step=6.96e-6, midlegL1_step=4.16e-6, hindlegR1_step=2.41e-5, hindlegL1_step=1.39e-5, train_loss_step=1.73e-5, learning_rate_step=0.0001, val_loss_step=8.04e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=4.16e-5, thorax1_epoch=3.39e-5, abdomen1_epoch=3.3e-5, forelegR1_epoch=2.41e-5, forelegL1_epoch=2.3e-5, midlegR1_epoch=1.84e-5, midlegL1_epoch=3.68e-5, hindlegR1_epoch=1.26e-5, hindlegL1_epoch=2.02e-5, train_loss_epoch=2.71e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.90it/s]\u001b[A\n",
            "Epoch 22: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=1.99e-5, thorax1_step=1.94e-5, abdomen1_step=4.75e-5, forelegR1_step=3.36e-6, forelegL1_step=8.15e-6, midlegR1_step=4.71e-6, midlegL1_step=1.7e-5, hindlegR1_step=5.36e-6, hindlegL1_step=8.06e-6, train_loss_step=1.48e-5, learning_rate_step=0.0001, val_loss_step=6.73e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.00012, head1_epoch=3.61e-5, thorax1_epoch=3.07e-5, abdomen1_epoch=3.06e-5, forelegR1_epoch=1.8e-5, forelegL1_epoch=1.7e-5, midlegR1_epoch=1.46e-5, midlegL1_epoch=2.63e-5, hindlegR1_epoch=1.73e-5, hindlegL1_epoch=1.59e-5, train_loss_epoch=2.29e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.71it/s]\u001b[A\n",
            "Epoch 23: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=1.61e-5, thorax1_step=1.5e-5, abdomen1_step=2.52e-5, forelegR1_step=3.77e-6, forelegL1_step=1.54e-6, midlegR1_step=2.2e-6, midlegL1_step=3.24e-6, hindlegR1_step=7.45e-6, hindlegL1_step=1.01e-6, train_loss_step=8.4e-6, learning_rate_step=0.0001, val_loss_step=8.24e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=3.24e-5, thorax1_epoch=2.25e-5, abdomen1_epoch=2.77e-5, forelegR1_epoch=1.93e-5, forelegL1_epoch=1.52e-5, midlegR1_epoch=1.2e-5, midlegL1_epoch=3.21e-5, hindlegR1_epoch=1.52e-5, hindlegL1_epoch=2.4e-5, train_loss_epoch=2.23e-5]  \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.93it/s]\u001b[A\n",
            "Epoch 24: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=8.84e-6, thorax1_step=2.11e-5, abdomen1_step=1.11e-5, forelegR1_step=3.3e-6, forelegL1_step=6.58e-6, midlegR1_step=2.64e-6, midlegL1_step=7.47e-6, hindlegR1_step=2.74e-6, hindlegL1_step=3.15e-6, train_loss_step=7.43e-6, learning_rate_step=0.0001, val_loss_step=8.52e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000113, head1_epoch=2.44e-5, thorax1_epoch=1.68e-5, abdomen1_epoch=2.52e-5, forelegR1_epoch=1.32e-5, forelegL1_epoch=1.13e-5, midlegR1_epoch=8.8e-6, midlegL1_epoch=3.37e-5, hindlegR1_epoch=1.45e-5, hindlegL1_epoch=2.82e-5, train_loss_epoch=1.96e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.89it/s]\u001b[A\n",
            "Epoch 25: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=1.77e-5, thorax1_step=8.7e-6, abdomen1_step=2.42e-5, forelegR1_step=6.74e-6, forelegL1_step=8.51e-6, midlegR1_step=3.93e-6, midlegL1_step=6.49e-6, hindlegR1_step=1.68e-6, hindlegL1_step=1.67e-5, train_loss_step=1.05e-5, learning_rate_step=0.0001, val_loss_step=9.34e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000119, head1_epoch=2.06e-5, thorax1_epoch=1.22e-5, abdomen1_epoch=1.84e-5, forelegR1_epoch=9.67e-6, forelegL1_epoch=9.54e-6, midlegR1_epoch=7.05e-6, midlegL1_epoch=2.74e-5, hindlegR1_epoch=5.4e-6, hindlegL1_epoch=1.02e-5, train_loss_epoch=1.34e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.15it/s]\u001b[A\n",
            "Epoch 26: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=1.21e-5, thorax1_step=7.87e-6, abdomen1_step=1.77e-5, forelegR1_step=3.87e-6, forelegL1_step=5.27e-6, midlegR1_step=3.98e-6, midlegL1_step=4.22e-6, hindlegR1_step=1.31e-6, hindlegL1_step=5.11e-6, train_loss_step=6.82e-6, learning_rate_step=0.0001, val_loss_step=8.91e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000125, head1_epoch=1.98e-5, thorax1_epoch=1.08e-5, abdomen1_epoch=1.66e-5, forelegR1_epoch=9.66e-6, forelegL1_epoch=8.78e-6, midlegR1_epoch=6.89e-6, midlegL1_epoch=2.1e-5, hindlegR1_epoch=3.78e-6, hindlegL1_epoch=8.05e-6, train_loss_epoch=1.17e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.92it/s]\u001b[A\n",
            "Epoch 27: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=1.7e-5, thorax1_step=1.91e-5, abdomen1_step=1.66e-5, forelegR1_step=5.2e-6, forelegL1_step=6.76e-6, midlegR1_step=2.98e-6, midlegL1_step=4.25e-6, hindlegR1_step=4.69e-6, hindlegL1_step=5.2e-6, train_loss_step=9.08e-6, learning_rate_step=0.0001, val_loss_step=9.31e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000114, head1_epoch=2.03e-5, thorax1_epoch=1.06e-5, abdomen1_epoch=1.47e-5, forelegR1_epoch=9.25e-6, forelegL1_epoch=7.01e-6, midlegR1_epoch=6.98e-6, midlegL1_epoch=1.67e-5, hindlegR1_epoch=3.78e-6, hindlegL1_epoch=3.92e-6, train_loss_epoch=1.04e-5]    \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.25it/s]\u001b[A\n",
            "Epoch 28: 100% 200/200 [01:07<00:00,  2.94it/s, head1_step=9.05e-6, thorax1_step=1.14e-5, abdomen1_step=1.06e-5, forelegR1_step=6.06e-6, forelegL1_step=2.69e-6, midlegR1_step=1.13e-6, midlegL1_step=1.18e-5, hindlegR1_step=2.63e-6, hindlegL1_step=7.26e-7, train_loss_step=6.23e-6, learning_rate_step=0.0001, val_loss_step=0.000106, learning_rate_epoch=0.0001, val_loss_epoch=0.000123, head1_epoch=2e-5, thorax1_epoch=1.13e-5, abdomen1_epoch=1.34e-5, forelegR1_epoch=9.04e-6, forelegL1_epoch=8.68e-6, midlegR1_epoch=6.27e-6, midlegL1_epoch=1.34e-5, hindlegR1_epoch=3.13e-6, hindlegL1_epoch=2.76e-6, train_loss_epoch=9.76e-6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.90it/s]\u001b[A\n",
            "Epoch 29: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=1.83e-5, thorax1_step=1.35e-5, abdomen1_step=2.47e-5, forelegR1_step=5.71e-6, forelegL1_step=2.16e-6, midlegR1_step=2.36e-6, midlegL1_step=2.86e-6, hindlegR1_step=4.45e-6, hindlegL1_step=3.05e-6, train_loss_step=8.56e-6, learning_rate_step=0.0001, val_loss_step=0.000102, learning_rate_epoch=0.0001, val_loss_epoch=0.000126, head1_epoch=2e-5, thorax1_epoch=1.25e-5, abdomen1_epoch=1.38e-5, forelegR1_epoch=9.11e-6, forelegL1_epoch=6.56e-6, midlegR1_epoch=3.33e-6, midlegL1_epoch=1.17e-5, hindlegR1_epoch=2.53e-6, hindlegL1_epoch=2.44e-6, train_loss_epoch=9.11e-6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.01it/s]\u001b[A\n",
            "Epoch 30: 100% 200/200 [01:07<00:00,  2.97it/s, head1_step=2.1e-5, thorax1_step=3.21e-5, abdomen1_step=1.8e-5, forelegR1_step=4.75e-6, forelegL1_step=1.72e-5, midlegR1_step=6.39e-6, midlegL1_step=1.31e-5, hindlegR1_step=1.15e-5, hindlegL1_step=4.51e-6, train_loss_step=1.43e-5, learning_rate_step=0.0001, val_loss_step=0.000105, learning_rate_epoch=0.0001, val_loss_epoch=0.000119, head1_epoch=2.31e-5, thorax1_epoch=1.57e-5, abdomen1_epoch=1.75e-5, forelegR1_epoch=1.03e-5, forelegL1_epoch=5.35e-6, midlegR1_epoch=3.17e-6, midlegL1_epoch=1.12e-5, hindlegR1_epoch=2.79e-6, hindlegL1_epoch=2.52e-6, train_loss_epoch=1.02e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.00it/s]\u001b[A\n",
            "Epoch 31: 100% 200/200 [01:07<00:00,  2.96it/s, head1_step=6.24e-5, thorax1_step=6.96e-5, abdomen1_step=3.87e-5, forelegR1_step=5.65e-5, forelegL1_step=1.07e-5, midlegR1_step=9.87e-6, midlegL1_step=2.99e-5, hindlegR1_step=6.4e-5, hindlegL1_step=7.29e-6, train_loss_step=3.88e-5, learning_rate_step=0.0001, val_loss_step=7.95e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000127, head1_epoch=2.98e-5, thorax1_epoch=2.11e-5, abdomen1_epoch=2e-5, forelegR1_epoch=1.1e-5, forelegL1_epoch=1.25e-5, midlegR1_epoch=3.83e-6, midlegL1_epoch=1.14e-5, hindlegR1_epoch=4.09e-6, hindlegL1_epoch=3.65e-6, train_loss_epoch=1.3e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.88it/s]\u001b[A\n",
            "Epoch 32: 100% 200/200 [01:07<00:00,  2.95it/s, head1_step=4.33e-5, thorax1_step=1.58e-5, abdomen1_step=2.54e-5, forelegR1_step=0.000387, forelegL1_step=8.11e-6, midlegR1_step=4.13e-5, midlegL1_step=6.59e-6, hindlegR1_step=1.24e-5, hindlegL1_step=4.39e-6, train_loss_step=6.05e-5, learning_rate_step=0.0001, val_loss_step=0.000119, learning_rate_epoch=0.0001, val_loss_epoch=0.000168, head1_epoch=2.35e-5, thorax1_epoch=1.69e-5, abdomen1_epoch=1.93e-5, forelegR1_epoch=2.17e-5, forelegL1_epoch=1.75e-5, midlegR1_epoch=1.64e-5, midlegL1_epoch=1.68e-5, hindlegR1_epoch=6.56e-6, hindlegL1_epoch=5.64e-6, train_loss_epoch=1.6e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Epoch 33: 100% 200/200 [01:07<00:00,  2.97it/s, head1_step=3.59e-5, thorax1_step=4.15e-5, abdomen1_step=3.16e-5, forelegR1_step=5.05e-6, forelegL1_step=1.04e-5, midlegR1_step=4.57e-6, midlegL1_step=5.92e-6, hindlegR1_step=0.000157, hindlegL1_step=1.05e-6, train_loss_step=3.26e-5, learning_rate_step=0.0001, val_loss_step=9.56e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.00012, head1_epoch=3.58e-5, thorax1_epoch=2.8e-5, abdomen1_epoch=3.88e-5, forelegR1_epoch=3.43e-5, forelegL1_epoch=2.7e-5, midlegR1_epoch=4.35e-5, midlegL1_epoch=7.3e-5, hindlegR1_epoch=4.38e-5, hindlegL1_epoch=6.1e-5, train_loss_epoch=4.28e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 34: 100% 200/200 [01:07<00:00,  2.98it/s, head1_step=1.26e-5, thorax1_step=7.8e-6, abdomen1_step=1.17e-5, forelegR1_step=3.19e-6, forelegL1_step=2.83e-6, midlegR1_step=6.38e-6, midlegL1_step=4.11e-6, hindlegR1_step=5.2e-6, hindlegL1_step=1.05e-5, train_loss_step=7.15e-6, learning_rate_step=0.0001, val_loss_step=7.9e-5, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=2.82e-5, thorax1_epoch=2.02e-5, abdomen1_epoch=3.23e-5, forelegR1_epoch=1.85e-5, forelegL1_epoch=1.83e-5, midlegR1_epoch=1.65e-5, midlegL1_epoch=4.3e-5, hindlegR1_epoch=2.19e-5, hindlegL1_epoch=3.56e-5, train_loss_epoch=2.61e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.08it/s]\u001b[A\n",
            "Epoch 35: 100% 200/200 [01:06<00:00,  2.99it/s, head1_step=1.78e-5, thorax1_step=5.81e-6, abdomen1_step=6.4e-6, forelegR1_step=4.9e-6, forelegL1_step=8.86e-6, midlegR1_step=1.37e-5, midlegL1_step=2.53e-6, hindlegR1_step=1.65e-6, hindlegL1_step=8.71e-6, train_loss_step=7.82e-6, learning_rate_step=0.0001, val_loss_step=0.000115, learning_rate_epoch=0.0001, val_loss_epoch=0.000113, head1_epoch=1.58e-5, thorax1_epoch=1.1e-5, abdomen1_epoch=1.72e-5, forelegR1_epoch=1.18e-5, forelegL1_epoch=9.72e-6, midlegR1_epoch=6.55e-6, midlegL1_epoch=2.19e-5, hindlegR1_epoch=1.37e-5, hindlegL1_epoch=1.1e-5, train_loss_epoch=1.32e-5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.04it/s]\u001b[A\n",
            "Epoch 36: 100% 200/200 [01:07<00:00,  2.98it/s, head1_step=1.64e-5, thorax1_step=1.12e-5, abdomen1_step=4.3e-6, forelegR1_step=1.61e-5, forelegL1_step=9.46e-6, midlegR1_step=3.74e-6, midlegL1_step=1.94e-5, hindlegR1_step=3.88e-6, hindlegL1_step=1.39e-6, train_loss_step=9.53e-6, learning_rate_step=0.0001, val_loss_step=0.000118, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=1.16e-5, thorax1_epoch=9.16e-6, abdomen1_epoch=1.36e-5, forelegR1_epoch=8.91e-6, forelegL1_epoch=5.23e-6, midlegR1_epoch=3.14e-6, midlegL1_epoch=9.89e-6, hindlegR1_epoch=2.96e-6, hindlegL1_epoch=2.97e-6, train_loss_epoch=7.5e-6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "Epoch 37: 100% 200/200 [01:07<00:00,  2.98it/s, head1_step=2.26e-5, thorax1_step=1.89e-5, abdomen1_step=1.66e-5, forelegR1_step=4.96e-6, forelegL1_step=6.09e-6, midlegR1_step=3.21e-6, midlegL1_step=4.5e-6, hindlegR1_step=5e-6, hindlegL1_step=6.97e-7, train_loss_step=9.17e-6, learning_rate_step=0.0001, val_loss_step=0.000117, learning_rate_epoch=0.0001, val_loss_epoch=0.000122, head1_epoch=1.06e-5, thorax1_epoch=9.93e-6, abdomen1_epoch=1.35e-5, forelegR1_epoch=9.08e-6, forelegL1_epoch=4.42e-6, midlegR1_epoch=2.82e-6, midlegL1_epoch=7.38e-6, hindlegR1_epoch=2.84e-6, hindlegL1_epoch=2.25e-6, train_loss_epoch=6.97e-6]   \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.83it/s]\u001b[A\n",
            "Epoch 38: 100% 200/200 [01:07<00:00,  2.98it/s, head1_step=1.36e-5, thorax1_step=8.52e-6, abdomen1_step=9.15e-6, forelegR1_step=1.82e-6, forelegL1_step=3.93e-6, midlegR1_step=2.77e-6, midlegL1_step=4.46e-6, hindlegR1_step=3.15e-6, hindlegL1_step=4.82e-6, train_loss_step=5.8e-6, learning_rate_step=0.0001, val_loss_step=0.00013, learning_rate_epoch=0.0001, val_loss_epoch=0.000127, head1_epoch=1.47e-5, thorax1_epoch=1.49e-5, abdomen1_epoch=1.7e-5, forelegR1_epoch=1.12e-5, forelegL1_epoch=6.42e-6, midlegR1_epoch=4.38e-6, midlegL1_epoch=8.41e-6, hindlegR1_epoch=4.06e-6, hindlegL1_epoch=2.77e-6, train_loss_epoch=9.32e-6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  7.09it/s]\u001b[A\n",
            "Epoch 39: 100% 200/200 [01:06<00:00,  2.99it/s, head1_step=9.74e-6, thorax1_step=6.79e-6, abdomen1_step=1.04e-5, forelegR1_step=1.61e-6, forelegL1_step=2.25e-6, midlegR1_step=1.91e-6, midlegL1_step=4.16e-6, hindlegR1_step=1.41e-6, hindlegL1_step=7.25e-7, train_loss_step=4.34e-6, learning_rate_step=0.0001, val_loss_step=0.000108, learning_rate_epoch=0.0001, val_loss_epoch=0.000103, head1_epoch=2.79e-5, thorax1_epoch=2.16e-5, abdomen1_epoch=2.4e-5, forelegR1_epoch=1.94e-5, forelegL1_epoch=1.84e-5, midlegR1_epoch=8.3e-6, midlegL1_epoch=1.3e-5, hindlegR1_epoch=6.22e-6, hindlegL1_epoch=5.28e-6, train_loss_epoch=1.6e-5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 8/8 [00:01<00:00,  6.12it/s]\u001b[A\n",
            "Epoch 39: 100% 200/200 [01:09<00:00,  2.89it/s, head1_step=9.74e-6, thorax1_step=6.79e-6, abdomen1_step=1.04e-5, forelegR1_step=1.61e-6, forelegL1_step=2.25e-6, midlegR1_step=1.91e-6, midlegL1_step=4.16e-6, hindlegR1_step=1.41e-6, hindlegL1_step=7.25e-7, train_loss_step=4.34e-6, learning_rate_step=0.0001, val_loss_step=0.00011, learning_rate_epoch=0.0001, val_loss_epoch=0.000115, head1_epoch=1.4e-5, thorax1_epoch=1.09e-5, abdomen1_epoch=1.31e-5, forelegR1_epoch=9.63e-6, forelegL1_epoch=9.9e-6, midlegR1_epoch=1.17e-5, midlegL1_epoch=1.3e-5, hindlegR1_epoch=2.94e-6, hindlegL1_epoch=2.81e-6, train_loss_epoch=9.79e-6]\n",
            "2025-10-20 10:18:04 | INFO | sleap_nn.training.model_trainer:train:1037 | Finished training loop. [47.2 min]\n",
            "2025-10-20 10:18:04 | INFO | sleap_nn.training.model_trainer:train:1064 | Deleting viz folder at models/drosophila_unet_64_251020_093034/viz...\n",
            "INFO:sleap.legacy_cli_adaptors:Finished training at: 2025-10-20 10:18:04.719754\n",
            "INFO:sleap.legacy_cli_adaptors:Total training time: 2834.197971343994 secs\n",
            "INFO:sleap.legacy_cli_adaptors:Training Config: data_config:\n",
            "  train_labels_path:\n",
            "  - colab.pkg.slp\n",
            "  val_labels_path: null\n",
            "  validation_fraction: 0.1\n",
            "  test_file_path: null\n",
            "  provider: LabelsReader\n",
            "  user_instances_only: true\n",
            "  data_pipeline_fw: torch_dataset\n",
            "  cache_img_path: null\n",
            "  use_existing_imgs: false\n",
            "  delete_cache_imgs_after_training: true\n",
            "  preprocessing:\n",
            "    ensure_rgb: true\n",
            "    ensure_grayscale: false\n",
            "    max_height: 182\n",
            "    max_width: 682\n",
            "    scale: 1.0\n",
            "    crop_size: null\n",
            "    min_crop_size: 100\n",
            "  use_augmentations_train: false\n",
            "  augmentation_config:\n",
            "    intensity:\n",
            "      uniform_noise_min: 0.0\n",
            "      uniform_noise_max: 1.0\n",
            "      uniform_noise_p: 0.0\n",
            "      gaussian_noise_mean: 5.0\n",
            "      gaussian_noise_std: 0.0\n",
            "      gaussian_noise_p: 0.0\n",
            "      contrast_min: 0.5\n",
            "      contrast_max: 1.75\n",
            "      contrast_p: 0.0\n",
            "      brightness_min: 0.0\n",
            "      brightness_max: 2.0\n",
            "      brightness_p: 0.0\n",
            "    geometric:\n",
            "      rotation_min: -15.0\n",
            "      rotation_max: 15.0\n",
            "      scale_min: 0.9\n",
            "      scale_max: 1.1\n",
            "      translate_width: 0.0\n",
            "      translate_height: 0.0\n",
            "      affine_p: 1.0\n",
            "      erase_scale_min: 0.0001\n",
            "      erase_scale_max: 0.01\n",
            "      erase_ratio_min: 1.0\n",
            "      erase_ratio_max: 1.0\n",
            "      erase_p: 0.0\n",
            "      mixup_lambda_min: 0.01\n",
            "      mixup_lambda_max: 0.05\n",
            "      mixup_p: 0.0\n",
            "  skeletons:\n",
            "  - nodes:\n",
            "    - name: head1\n",
            "    - name: thorax1\n",
            "    - name: abdomen1\n",
            "    - name: forelegR1\n",
            "    - name: forelegL1\n",
            "    - name: midlegR1\n",
            "    - name: midlegL1\n",
            "    - name: hindlegR1\n",
            "    - name: hindlegL1\n",
            "    edges:\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: head1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: abdomen1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: forelegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: forelegL1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: midlegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: midlegL1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: hindlegR1\n",
            "    - source:\n",
            "        name: thorax1\n",
            "      destination:\n",
            "        name: hindlegL1\n",
            "    symmetries:\n",
            "    - - name: forelegL1\n",
            "      - name: forelegR1\n",
            "    - - name: midlegR1\n",
            "      - name: midlegL1\n",
            "    - - name: hindlegR1\n",
            "      - name: hindlegL1\n",
            "    name: Skeleton-0\n",
            "model_config:\n",
            "  init_weights: default\n",
            "  pretrained_backbone_weights: null\n",
            "  pretrained_head_weights: null\n",
            "  backbone_config:\n",
            "    unet:\n",
            "      in_channels: 3\n",
            "      kernel_size: 3\n",
            "      filters: 64\n",
            "      filters_rate: 1.5\n",
            "      max_stride: 32\n",
            "      stem_stride: null\n",
            "      middle_block: true\n",
            "      up_interpolate: true\n",
            "      stacks: 1\n",
            "      convs_per_block: 2\n",
            "      output_stride: 4\n",
            "    convnext: null\n",
            "    swint: null\n",
            "  head_configs:\n",
            "    single_instance:\n",
            "      confmaps:\n",
            "        part_names:\n",
            "        - head1\n",
            "        - thorax1\n",
            "        - abdomen1\n",
            "        - forelegR1\n",
            "        - forelegL1\n",
            "        - midlegR1\n",
            "        - midlegL1\n",
            "        - hindlegR1\n",
            "        - hindlegL1\n",
            "        sigma: 2.5\n",
            "        output_stride: 4\n",
            "    centroid: null\n",
            "    centered_instance: null\n",
            "    bottomup: null\n",
            "    multi_class_bottomup: null\n",
            "    multi_class_topdown: null\n",
            "  total_params: 11740217\n",
            "trainer_config:\n",
            "  train_data_loader:\n",
            "    batch_size: 6\n",
            "    shuffle: false\n",
            "    num_workers: 0\n",
            "  val_data_loader:\n",
            "    batch_size: 6\n",
            "    shuffle: false\n",
            "    num_workers: 0\n",
            "  model_ckpt:\n",
            "    save_top_k: 1\n",
            "    save_last: false\n",
            "  trainer_devices: auto\n",
            "  trainer_device_indices: null\n",
            "  trainer_accelerator: auto\n",
            "  profiler: null\n",
            "  trainer_strategy: auto\n",
            "  enable_progress_bar: true\n",
            "  min_train_steps_per_epoch: 200\n",
            "  train_steps_per_epoch: 200\n",
            "  visualize_preds_during_training: true\n",
            "  keep_viz: false\n",
            "  max_epochs: 200\n",
            "  seed: 42\n",
            "  use_wandb: false\n",
            "  save_ckpt: true\n",
            "  ckpt_dir: models\n",
            "  run_name: drosophila_unet_64_251020_093034\n",
            "  resume_ckpt_path: null\n",
            "  wandb:\n",
            "    entity: ''\n",
            "    project: ''\n",
            "    name: ''\n",
            "    save_viz_imgs_wandb: false\n",
            "    api_key: ''\n",
            "    wandb_mode: null\n",
            "    prv_runid: ''\n",
            "    group: ''\n",
            "    current_run_id: null\n",
            "  optimizer_name: Adam\n",
            "  optimizer:\n",
            "    lr: 0.0001\n",
            "    amsgrad: false\n",
            "  lr_scheduler: null\n",
            "  early_stopping:\n",
            "    min_delta: 1.0e-08\n",
            "    patience: 20\n",
            "    stop_training_on_plateau: true\n",
            "  online_hard_keypoint_mining:\n",
            "    online_mining: false\n",
            "    hard_to_easy_ratio: 2.0\n",
            "    min_hard_keypoints: 2\n",
            "    max_hard_keypoints: null\n",
            "    loss_scale: 5.0\n",
            "  zmq:\n",
            "    controller_port: null\n",
            "    controller_polling_timeout: 10\n",
            "    publish_port: null\n",
            "name: ''\n",
            "description: ''\n",
            "sleap_nn_version: 0.0.2\n",
            "filename: ''\n",
            "\n",
            "INFO:sleap.legacy_cli_adaptors:Training labels path for index 0: models/drosophila_unet_64_251020_093034\n",
            "2025-10-20 10:18:05 | INFO | sleap_nn.predict:run_inference:319 | Started inference at: 2025-10-20 10:18:05.331824\n",
            "2025-10-20 10:18:05 | INFO | sleap_nn.predict:run_inference:335 | Using device: cuda:0\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m407/407\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m Elapsed: \u001b[33m0:00:07\u001b[0m \u001b[31m57.0 FPS\u001b[0m\n",
            "\u001b[?25h2025-10-20 10:18:13 | INFO | sleap_nn.predict:run_inference:453 | Finished inference at: 2025-10-20 10:18:13.413808\n",
            "2025-10-20 10:18:13 | INFO | sleap_nn.predict:run_inference:454 | Total runtime: 8.081997871398926 secs\n",
            "2025-10-20 10:18:13 | INFO | sleap_nn.predict:run_inference:465 | Predictions output path: models/drosophila_unet_64_251020_093034/pred_train_0.slp\n",
            "2025-10-20 10:18:13 | INFO | sleap_nn.predict:run_inference:466 | Saved file at: 2025-10-20 10:18:13.514119\n",
            "INFO:sleap.legacy_cli_adaptors:---------Evaluation on `train_0` dataset---------\n",
            "INFO:sleap.legacy_cli_adaptors:OKS mAP: 0.9250637640997359\n",
            "INFO:sleap.legacy_cli_adaptors:Average distance: 1.2486125030177135\n",
            "INFO:sleap.legacy_cli_adaptors:p90 dist: 2.031383833447945\n",
            "INFO:sleap.legacy_cli_adaptors:p50 dist: 1.1771228316233742\n",
            "2025-10-20 10:18:14 | INFO | sleap_nn.predict:run_inference:319 | Started inference at: 2025-10-20 10:18:14.282865\n",
            "2025-10-20 10:18:14 | INFO | sleap_nn.predict:run_inference:335 | Using device: cuda:0\n",
            "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m45/45\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m Elapsed: \u001b[33m0:00:01\u001b[0m \u001b[31m42.4 FPS\u001b[0m\n",
            "\u001b[?25h2025-10-20 10:18:16 | INFO | sleap_nn.predict:run_inference:453 | Finished inference at: 2025-10-20 10:18:16.222880\n",
            "2025-10-20 10:18:16 | INFO | sleap_nn.predict:run_inference:454 | Total runtime: 1.9400303363800049 secs\n",
            "2025-10-20 10:18:16 | INFO | sleap_nn.predict:run_inference:465 | Predictions output path: models/drosophila_unet_64_251020_093034/pred_val_0.slp\n",
            "2025-10-20 10:18:16 | INFO | sleap_nn.predict:run_inference:466 | Saved file at: 2025-10-20 10:18:16.305650\n",
            "INFO:sleap.legacy_cli_adaptors:---------Evaluation on `val_0` dataset---------\n",
            "INFO:sleap.legacy_cli_adaptors:OKS mAP: 0.8029385772620103\n",
            "INFO:sleap.legacy_cli_adaptors:Average distance: 2.1962541771442594\n",
            "INFO:sleap.legacy_cli_adaptors:p90 dist: 2.6589667627881344\n",
            "INFO:sleap.legacy_cli_adaptors:p50 dist: 1.39981120010878\n"
          ]
        }
      ],
      "source": [
        "!sleap-train single_instance.yaml colab.pkg.slp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Files Generation"
      ],
      "metadata": {
        "id": "eGwiVzuu8-SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION\n",
        "# =========================================================\n",
        "MODELS_DIR = \"models\"   # parent folder containing model runs\n",
        "SAVE_FIGS = True        # save generated figures\n",
        "plt.rcParams.update({\"figure.dpi\": 120})\n",
        "\n",
        "# =========================================================\n",
        "# Locate latest model (by modification time)\n",
        "# =========================================================\n",
        "model_runs = sorted(glob.glob(os.path.join(MODELS_DIR, \"*\")), key=os.path.getmtime)\n",
        "if not model_runs:\n",
        "    raise FileNotFoundError(\"No model directories found in 'models/'. Check your path.\")\n",
        "latest_model = model_runs[-1]\n",
        "\n",
        "# Handle nested folder issue (model inside model)\n",
        "nested = os.path.join(latest_model, os.path.basename(latest_model))\n",
        "if os.path.isdir(nested):\n",
        "    print(f\" Detected nested run folder, using: {nested}\")\n",
        "    latest_model = nested\n",
        "\n",
        "print(f\"\\n Latest model directory: {latest_model}\")\n",
        "\n",
        "# =========================================================\n",
        "# Load training log (training_log.csv)\n",
        "# =========================================================\n",
        "metrics_path = os.path.join(latest_model, \"training_log.csv\")\n",
        "if not os.path.exists(metrics_path):\n",
        "    raise FileNotFoundError(f\"No training_log.csv found in {latest_model}\")\n",
        "\n",
        "df = pd.read_csv(metrics_path)\n",
        "if \"epoch\" not in df.columns:\n",
        "    raise ValueError(\"training_log.csv missing 'epoch' column; check SLEAP output\")\n",
        "\n",
        "print(f\"\\n Metrics loaded successfully ({len(df)} epochs).\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# =========================================================\n",
        "# Identify best epoch (minimum validation loss)\n",
        "# =========================================================\n",
        "best_idx = df[\"val_loss\"].idxmin()\n",
        "best_row = df.loc[best_idx]\n",
        "best_epoch = int(best_row[\"epoch\"])\n",
        "best_val_loss = best_row[\"val_loss\"]\n",
        "best_train_loss = best_row[\"train_loss\"]\n",
        "loss_ratio = best_val_loss / best_train_loss if best_train_loss != 0 else None\n",
        "\n",
        "print(\"\\n Best Model Summary\")\n",
        "print(f\"  • Epoch: {best_epoch}\")\n",
        "print(f\"  • Validation Loss: {best_val_loss:.5f}\")\n",
        "print(f\"  • Training Loss:   {best_train_loss:.5f}\")\n",
        "print(f\"  • Val/Train Ratio: {loss_ratio:.3f} (≈1.0 ideal)\\n\")\n",
        "\n",
        "# =========================================================\n",
        "# Load evaluation metrics from .npz files\n",
        "# =========================================================\n",
        "train_npz = os.path.join(latest_model, \"train_0_pred_metrics.npz\")\n",
        "val_npz = os.path.join(latest_model, \"val_0_pred_metrics.npz\")\n",
        "\n",
        "def load_npz_metrics(npz_path, label):\n",
        "    \"\"\"Extract OKS, distance, and percentile metrics from SLEAP .npz result files (robust to nested dicts).\"\"\"\n",
        "    if not os.path.exists(npz_path):\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        data = np.load(npz_path, allow_pickle=True)\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to read {npz_path}: {e}\")\n",
        "        return {}\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # 1️ Mean OKS (object keypoint similarity)\n",
        "    if \"mOKS.npy\" in data.files or \"mOKS\" in data:\n",
        "        moks = data[\"mOKS.npy\"] if \"mOKS.npy\" in data.files else data[\"mOKS\"]\n",
        "        if isinstance(moks, np.ndarray):\n",
        "            # unwrap nested dict if needed\n",
        "            try:\n",
        "                if moks.dtype == \"O\" and isinstance(moks.item(), dict):\n",
        "                    moks = list(moks.item().values())\n",
        "            except Exception:\n",
        "                pass\n",
        "            metrics[f\"{label}_OKS_mAP\"] = float(np.nanmean(moks))\n",
        "\n",
        "    # 2 Distance metrics\n",
        "    if \"distance_metrics.npy\" in data.files or \"distance_metrics\" in data:\n",
        "        dist = data[\"distance_metrics.npy\"] if \"distance_metrics.npy\" in data.files else data[\"distance_metrics\"]\n",
        "        if isinstance(dist, np.ndarray) and dist.dtype == \"O\":\n",
        "            try:\n",
        "                d = dist.item()\n",
        "                if isinstance(d, dict):\n",
        "                    for k in [\"mean\", \"p50\", \"p90\"]:\n",
        "                        if k in d:\n",
        "                            val = d[k]\n",
        "                            # unwrap nested dicts or arrays\n",
        "                            if isinstance(val, dict):\n",
        "                                val = list(val.values())\n",
        "                            metrics[f\"{label}_{k if k!='mean' else 'avg'}_dist\"] = float(np.nanmean(val))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # 3 Pose correctness (PCK)\n",
        "    if \"pck_metrics.npy\" in data.files:\n",
        "        pck = data[\"pck_metrics.npy\"].item()\n",
        "        if isinstance(pck, dict) and \"mean\" in pck:\n",
        "            val = pck[\"mean\"]\n",
        "            if isinstance(val, dict):\n",
        "                val = list(val.values())\n",
        "            metrics[f\"{label}_PCK_mean\"] = float(np.nanmean(val))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "extra_metrics = {}\n",
        "extra_metrics.update(load_npz_metrics(train_npz, \"train\"))\n",
        "extra_metrics.update(load_npz_metrics(val_npz, \"val\"))\n",
        "\n",
        "if extra_metrics:\n",
        "    print(\" Evaluation metrics (.npz):\")\n",
        "    for k, v in extra_metrics.items():\n",
        "        if not np.isnan(v):\n",
        "            print(f\"  • {k}: {v:.4f}\")\n",
        "else:\n",
        "    print(\" No valid .npz metrics detected (train_0_pred_metrics.npz / val_0_pred_metrics.npz).\")\n",
        "\n",
        "# =========================================================\n",
        "# Estimate runtime (if available)\n",
        "# =========================================================\n",
        "runtime_sec = None\n",
        "try:\n",
        "    if \"train_time\" in df.columns and \"val_time\" in df.columns:\n",
        "        runtime_sec = df[\"train_time\"].sum() + df[\"val_time\"].sum()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# =========================================================\n",
        "# Plot training vs validation losses\n",
        "# =========================================================\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "if SAVE_FIGS:\n",
        "    loss_fig_path = os.path.join(latest_model, f\"loss_curve_{datetime.now().strftime('%Y%m%d_%H%M')}.png\")\n",
        "    plt.savefig(loss_fig_path, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\" Saved loss curve: {loss_fig_path}\")\n",
        "plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# Per-keypoint validation losses\n",
        "# =========================================================\n",
        "keypoint_cols = [c for c in df.columns if any(k in c for k in [\"head\", \"thorax\", \"leg\", \"abdomen\"])]\n",
        "\n",
        "if keypoint_cols:\n",
        "    best_keypoint_losses = df.loc[best_idx, keypoint_cols].sort_values()\n",
        "    print(\"\\n Per-keypoint validation losses (best epoch):\")\n",
        "    print(best_keypoint_losses.round(6).to_string())\n",
        "\n",
        "    plt.figure(figsize=(9,5))\n",
        "    best_keypoint_losses.plot.bar()\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Per-Keypoint Validation Losses (Epoch {best_epoch})\")\n",
        "    plt.grid(True, axis='y')\n",
        "    if SAVE_FIGS:\n",
        "        kp_fig_path = os.path.join(latest_model, f\"keypoint_losses_{datetime.now().strftime('%Y%m%d_%H%M')}.png\")\n",
        "        plt.savefig(kp_fig_path, dpi=300, bbox_inches=\"tight\")\n",
        "        print(f\"📊 Saved keypoint loss plot: {kp_fig_path}\")\n",
        "    plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# Export summary metrics to CSV\n",
        "# =========================================================\n",
        "summary = {\n",
        "    \"model_dir\": latest_model,\n",
        "    \"best_epoch\": best_epoch,\n",
        "    \"val_loss\": best_val_loss,\n",
        "    \"train_loss\": best_train_loss,\n",
        "    \"val/train_ratio\": loss_ratio,\n",
        "    \"runtime_sec\": runtime_sec,\n",
        "    \"num_epochs\": len(df),\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "}\n",
        "summary.update(extra_metrics)\n",
        "\n",
        "summary_df = pd.DataFrame([summary])\n",
        "summary_csv_path = os.path.join(latest_model, \"summary_metrics.csv\")\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "\n",
        "print(f\"\\n Summary metrics saved to: {summary_csv_path}\")\n",
        "print(\"\\n Done! Generated inside model folder:\")\n",
        "print(\"  • loss_curve_*.png → Training curve\")\n",
        "print(\"  • keypoint_losses_*.png → Per-keypoint bar plot\")\n",
        "print(\"  • summary_metrics.csv → Numerical report\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "-75_EKoM889R",
        "outputId": "1ce7c58e-5e88-4e26-8d9c-f787e5dcc9f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No model directories found in 'models/'. Check your path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1188311340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_runs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No model directories found in 'models/'. Check your path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mlatest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No model directories found in 'models/'. Check your path."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "If instead of bottom-up you've chosen the top-down pipeline (with two training configs), you would need to invoke two separate training jobs in sequence:\n",
        "\n",
        "- `!sleap-train centroid.json colab.pkg.slp`\n",
        "- `!sleap-train centered_instance.json colab.pkg.slp`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precictions Test Set"
      ],
      "metadata": {
        "id": "w51ilLxF9s9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# ============================================================\n",
        "# STEP 1: DEFINE PATHS AND PARAMETERS\n",
        "# ============================================================\n",
        "MODEL_NAME=\"drosophila_unet_64_251020_093034\"\n",
        "BASE_DIR=\"/content/drive/MyDrive/sleap\"\n",
        "MODEL_DIR=\"${BASE_DIR}/models/${MODEL_NAME}\"\n",
        "VIDEO_PATH=\"${BASE_DIR}/fly1.2.mp4\"\n",
        "\n",
        "# Output paths (all inside model folder)\n",
        "PREDICTIONS_DIR=\"${MODEL_DIR}/predictions\"\n",
        "mkdir -p \"${PREDICTIONS_DIR}\"\n",
        "\n",
        "PRED_FILE=\"${PREDICTIONS_DIR}/fly1.2.predictions.slp\"\n",
        "RENDER_FILE=\"${PREDICTIONS_DIR}/fly1.2.tracked.mp4\"\n",
        "\n",
        "echo \" Model directory: ${MODEL_DIR}\"\n",
        "echo \" Input video: ${VIDEO_PATH}\"\n",
        "echo \" Predictions output: ${PRED_FILE}\"\n",
        "echo \" Rendered video output: ${RENDER_FILE}\"\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: RUN INFERENCE (PREDICT ON VIDEO)\n",
        "# ============================================================\n",
        "# Correct modern SLEAP syntax:\n",
        "sleap-track \\\n",
        "    \"${VIDEO_PATH}\" \\\n",
        "    --model \"${MODEL_DIR}\" \\\n",
        "    --output \"${PRED_FILE}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7SuhUoW9rFq",
        "outputId": "ddb8a22c-05c5-40f9-b74a-67b5f3aed08c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model directory: /content/drive/MyDrive/sleap/models/drosophila_unet_64_251020_093034\n",
            " Input video: /content/drive/MyDrive/sleap/fly1.2.mp4\n",
            " Predictions output: /content/drive/MyDrive/sleap/models/drosophila_unet_64_251020_093034/predictions/fly1.2.predictions.slp\n",
            " Rendered video output: /content/drive/MyDrive/sleap/models/drosophila_unet_64_251020_093034/predictions/fly1.2.tracked.mp4\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2025-10-20 10:41:07 | INFO | sleap_nn.predict:run_inference:319 | Started inference at: 2025-10-20 10:41:07.802319\n",
            "2025-10-20 10:41:07 | INFO | sleap_nn.predict:run_inference:335 | Using device: cuda\n",
            "Predicting... ━━━━━━━━━━━━━━ 100% 147/147 ETA: 0:00:00 Elapsed: 0:00:03 53.4 FPS\n",
            "2025-10-20 10:41:11 | INFO | sleap_nn.predict:run_inference:453 | Finished inference at: 2025-10-20 10:41:11.691788\n",
            "2025-10-20 10:41:11 | INFO | sleap_nn.predict:run_inference:454 | Total runtime: 3.8894846439361572 secs\n",
            "2025-10-20 10:41:11 | INFO | sleap_nn.predict:run_inference:465 | Predictions output path: /content/drive/MyDrive/sleap/models/drosophila_unet_64_251020_093034/predictions/fly1.2.predictions.slp\n",
            "2025-10-20 10:41:11 | INFO | sleap_nn.predict:run_inference:466 | Saved file at: 2025-10-20 10:41:11.751304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the Predictions Video"
      ],
      "metadata": {
        "id": "w_Gr22ljDAZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/drive/MyDrive/sleap/models/drosophila_unet_1_251019_094425/predictions\n"
      ],
      "metadata": {
        "id": "ckYdrt4ACl9Y",
        "outputId": "9a7961ff-6520-41da-d639-5af52e0ed180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 53K\n",
            "-rw------- 1 root root 53K Oct 19 15:11 fly1.2.predictions.slp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/drive/MyDrive/sleap/models/drosophila_unet_1_251019_094425/predictions   # Desired Model Directory (CHANGE HERE)\n",
        "# The rendered video has bad quality compared to watching the predictions in the SLEAP GUI\n",
        "\n",
        "!sleap-render fly1.2.predictions.slp \\\n",
        "  --video-index 0 \\\n",
        "  -o labeled_video.mp4 \\\n",
        "  --scale 1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQvqtYJ-CyCJ",
        "outputId": "f1c2136e-7405-4120-81a8-b551eea972c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/sleap/models/drosophila_unet_1_251019_094425/predictions\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Saving config: /root/.sleap/1.5.1/preferences.yaml\n",
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (644, 200) to (656, 208) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Video saved as: labeled_video.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_and_inference_using_Google_Drive.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}